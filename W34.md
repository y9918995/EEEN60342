# 2.1 Introduction to Reliability of Non-Reparable and Reparable Component   
LECTURER:   
Hello, and welcome to section 5 of unit 7, Power System Dynamics and Quality of Supply.  
My name is Dr. Mathaios Panteli, And I am a lecture at the power and energy division of the school of Electrical and Electronic Engineering.  
We will be covering together section 5, reliability of non-repairable components.  
And section 6 reliability of generation complex systems.  
In section 5, we will start with the introduction to reliability.  
What it means, why is it important to us as power engineers.  
And where reliability analysis is useful and applied in power systems.  
We will then discuss and make clear the differences between non-repairable and repairable components.  
(INAUDIBLE) reliability and unreliability functions and reliability modelling.  
Looking for example of indifferent probability distribution we can use.  
Such as normal and (INAUDIBLE) distributions.  
It is also critical to understand that the failure rate is not constant over the life cycle of a component.  
In this context, we will also talk about the bathtub curve.  
And how to model this curve.  
Which is a very important concept demonstrating and helping us understand how the failure rate changes over the life cycle of a component.  
We will also cover together in this section the concept of steady state probabilities and reliability modelling of systems.  
For example, how we can model series and parallel systems from a reliability point of view.  
Talk about minimal tie sets cut set methods.  
Which are critical in power system reliability analysis.  
And finish the section, with (INAUDIBLE) analysis.  
Which is one of the most popular techniques for graphical representation of events linking to the failure of the considered system.  
     
# 2.2 Reliability of Non-Repairable Components   
## 2.2.1 Introduction to Reliability and Non-Repairable Components   
LECTURER:   
Welcome to the first video of Section 5 where we'll have a quick introduction to reliability and talk about non-reparable components, as well as go through and illustrate example at the end of this video.  
So, to begin with, what is reliability? When we're trying to design or develop a component or a system, we're really interested in knowing how reliable or how safe will the system be during its future operating life? And this is important from two aspects.  
Firstly, to reduce as much as possible the failures of the considered component during the period of the component or system is in service.  
And secondly, to design a system that will be safe and not pose any threats.  
A possible and one of the most known definitions is shown here where reliability is defined as a probability of a device performing its purpose adequately for the period of time intended under the operating conditions encountered.  
Now, we see from this definition that there are some key basic parts.  
The first is the probability of the device would perform its performance as expected which will be used as input for calculating the reliability indices which will be the output of the reliability analysis.  
So, in reliability analysis, we'll have different and multiple indices that can be calculated and used to compare the effectiveness of different design and implementation alternatives.  
Then, we'll have the concept of adequate performance which can be quantified in many ways.  
In our case, it is basically the ability of a power system to provide electrical supply in a secured and reliable way.  
Then, we'll have the time and operating conditions which is an engineering concept.  
The operating and also, the environmental conditions where the component experience might affect significantly is probably of failure.  
Think, for example, a component that is frequently exposed to extreme weather conditions.  
Compare the component which is not, which is basically only experiencing normal weather conditions.  
Studies actually show that extreme environments can increase the failure rate of a component by even ten times, so such conditions should be considered in the design and installation of the component.  
So, where is reliability analysis used in power systems? It is mainly applied in two areas, expansion planning and design of power systems, and operation planning and control of power systems.  
So, reliability analysis is basically critical in any aspect of power systems, from expansion planning to operation and control studies and strategies.  
Let's start with the first topic we'll cover in this section.  
We'll talk about what non-reparable and reparable components mean.  
First, let's clarify what we mean by component.  
A component can be any power system asset with having operation in service.  
For example, overhead lines, transformers, cables, circuit breakers, and protection device and so on.  
So, a non-reparable component is a component that experience failure and it cannot be repaired.  
If a component cannot be repaired it means that it needs to be replaced.  
Think for example of a transformer that caught fire which can happen for several reasons.  
For example, lightning strike, faulty wires, or insulation failure.  
Further to that, direct threat to human lives as these are very dangerous event, most of the times, it is not financially beneficial to repair the transformer.  
In such cases, the transformer is completely replaced.  
A reparable component is a component that failed, but it can be repaired within a reasonable period of time and at an acceptable cost.  
Now, let's see what the diagram in this slide shows which is called 'Bathtub Curve' because of the shape which looks like a bathtub.  
In the Y-axis, we have the failure rate of the component, and in the X-axis, the time which refers to the life cycle of the component.  
The time, basically, of the component is in service.  
The failure rate is the number of failures per time unit.  
Usually expressed per year by the manufacturers.  
First is the infant stage where the component's commissioned during which stage a component usually has a higher failure rate for different reasons.  
Then, we have the normal operating stage where the failure rate of the component is approximately constant and the component is considered reparable.  
Usually, this stage is the longest stage of the life cycle of a component, and it is a stage where we consider where the failures that the component will experience can be repaired.  
Then, let's say 30 or 40 years of the component being in service, it enters the wear-out stage where the component starts ageing, leading to increasing number of failures in any time unit, for example, per year.  
By no means, it doesn't mean that these failures cannot be repaired.  
If not catastrophic, of course.  
Meaning, leading to the complete destruction of the component, but it is more likely to be more beneficial to replace the component.  
So, we have two main categories or relevant studies.  
The replacement studies which refer to non-reparable components.  
And the reinforcement planning studies which refer to the...  
reparable components.  
There are some fundamental reliability functions that we need to first discuss to understand in more detail the concepts we're covering.  
In this context, we'll start with some fundamental concepts of reliability analysis based on which we'll build the upcoming material.  
So, what this reliability function which is shown in equation one that under variable T in this function refers to the in-service time because we're interested in knowing when the component will fail or with which probability it will fail.  
The reliability function, R(t), is a function of time.  
It is defined as the probability that the in-service time, T, is larger, is greater than the time started with installation.  
And the reliability is the Q(t) function which the probability that the in-service time is less than some variable t that we started the installation or in other words, 1 - R(t).  
So, we'll have two main functions.  
Reliability function which means the component survives not fails.  
And the unreliability function which refers to the failure of a component.  
Another important function is the failure density function which is defined as the ratio of the reliability function Q(t) over time or the negative ratio of reliability function R(t) over time.  
We'll see this concept later on in examples which can make everything much clearer.  
We also have the concepts of cumulative and density functions where unreliability and reliability are defined with the integrals given in equation 4 and 5 respectively.  
It will consider a random time (t) of the component installation.  
And reliability Q(t) is basically the integral of the failure density function F(t) from time 0 to time t.  
While the reliability function R(t) is the integral of the failure function from time t to infinity.  
This is shown in the diagram with this slide which shows the failure density function over time.  
Since we already saw that unreliability Q(t) is a probability that t is larger than the in-service time T.  
Unreliability Q(t) refers to the area on the left-hand side of time T where reliability R(t) refers to the area to the right-hand side of time T.  
Next, we're going to talk about some more general reliability functions which are really important to understand before moving on to applications of reliability analysis.  
First, we need to know what is the hazard rate function or the failure rate function.  
So, we define a failure rate as λ(t) which as mentioned is the number of failures per time unit usually per year.  
Please note that lambda is a function of time showing that it is possible but it is not constant over time.  
So, in this mathematical expression, equation 6, λ(t) is the condition of probability that the...  
In service time capital T is greater than t and less equal than t plus delta t.  
If under the condition that capital T is larger than t.  
Which means it didn't fail, it survived before lower t.  
Basically, capital T larger that lower t.  
Add all these together divided by delta t.  
If we consider two events, A and B.  
The conditional probability can be mathematically expressed as the probability of A times B.  
Divided by probability in B.  
So, if we use this mathematical expression in equation 6.  
We get the following expression of lambda t we see in equation 7.  
So, we will have the probability of capital T being larger than t.  
But less equal to t plus delta t times the probability of capital T being larger than t.  
Divided by delta t times the probability of capital T being larger than t.  
So, in the numerator the expression capital T larger than t is the same condition as in the first bracket.  
In the denominator, the probability of capital T being larger than t is the reliability function R(t) we saw earlier.  
So, the failure rate function lambda t can be expressed mathematically as the ratio of failure of density function, f(t) over the reliability function R(t).  
So, lambda t is basically the probability that the component fails in the interval t and t plus delta t.  
If it has not failed until t.  
This is basically the physical meaning of lambda t.  
The reliability function R(t) can now be obtained by integrating equation 7.  
By firstly, substituting the express failure density function f(t) equals minus d Rt over dt.  
So, the reliability function Rt can be expressed now as exponential function of the negative integral of lambda x in the time interval 0 to t.  
As in equation 8.  
Which gives us equation 9.  
Which shows that Rt can be expressed as the exponential function of the negative product of the failure rate lambda in time t.  
If lambda is now considered constant in the normal operating life stage of a component.  
This is a very important conclusion.  
Which drives numerous reliability studies and analysis.  
Another key concept is the so-called mean time to failure.  
Which is basically the length of time a component is expected to be in operation without any failure.  
Or in other words, the expected time that the component would fail.  
Please, be careful not to confuse this concept with the mean time between failures.  
Which shows the predict in time between incurring failures of a component during normal component operation.  
The mean time to failure is mathematically defined as the integral from 0 to infinity of the product t and the failure density function ft in dt.  
Which ultimately gives the mean time to failure equal to the integral of the reliability function from 0 to infinity.  
Having discussed the mathematical expressions of the failure rate.  
Let's visit again the bathtub curve.  
And talk about the failure rate in the different stages of the curve.  
During the normal operating stage the failure rate is considered approximately constant.  
So the failure density function is exponentially distributed.  
And can be expressed by equation 9 in the previous slide.  
However, we can see that in wear-out stage.  
The failure rate is monotonically increasing.  
So, we have different distributions that we can use for the failure density functions in this period.  
Usually, normal, lognormal and weibull distribution.  
We'll talk about this distribution later on in the next video.  
And more specifically for normal and weibull distributions.  
And we'll see how to express the failure or probability density functions using these distributions.  
Before we do that in the next video.  
Let's see an example to put numbers in the concept that we covered so we can understand them better.  
So, example one refers to the calculation of reliability functions from a data set.  
This data set is given in the next slide.  
For which we see what column is in this slide.  
In this table, the first column shows that time interval in hours.  
Basically starting from 0 going up to 19.  
The number of failures in each interval is given in the second column.  
The number of components of fail.  
For example, in hour 0, 140 components failed.  
In our 1, 85 components failures and so on.  
The cumulative failures, nf is given in the third column.  
Beginning from 0, 140 in the second row, 225 in the third row.  
By adding 140 and 85 and so on.  
Until hour 19.  
Where we have 1,000 failures.  
The number of the components in this example.  
The number of survivors ns fourth column is the difference between the number of components, 1,000 and the number of failures.  
For example, in the first row we have 1,000.  
Then, 1,000 minus 140, which gives 860.  
860 minus 85, which gives 775 and so on until 0 in the last row.  
The failure density function f column 5 is give by the ratio between the number of failures during a time interval.  
And total number of components 1,000.  
For example, in hour 0 it is 140 over 1,000.  
Which gives 0.14.  
Going all the way down to 0.  
In column 6, we have the cumulative failure distribution q.  
Which is the ratio between the cumulative number of failures and 1,000.  
Starting from 0 going up to one in the last row.  
In column 7, we have the survival function r.  
Which is the ratio between the number of survivals and 1,000.  
Or 1 minus q.  
The last column shows the hazard of failure rate lambda.  
Which is the ratio between the number of failures in an interval and the average number of survivors for that period.  
Which is slightly different from the definition we saw before.  
A few examples are given in the previous slide for calculating the failure rate right here at the bottom.  
So, for the first interval it is the number of failures 140 over the sum of 1,000 and 860 divided by 2 to get the average.  
Which gives 0.151.  
In the second interval, it is the number of failures in interval 1, which is 85, over the sum of 860 and 775 divided by 2.  
Which gives 0.104 and so on.  
In this slide, we can see some plots relevant to this example.  
On the top left plot, we can see that the failure rate is higher for a few hours in stage 1, in first stage.  
And decreasing.  
Then, in stage 2 the normal operating stage.  
The failure rate drops.  
And it remains approximately constant around 0.1.  
Flowing this stage, we enter stage 3 in the 12 time interval.  
The wear-out stage.  
Where the failure rate increases sharply up to the value of failure rate equal to 2.  
In the top right figure, we can see the reliability or survival function.  
Which decays over time quite rapidly starting from 1 and going down to 0 at hour 19.  
The failure density function in the bottom left figure is quite interesting.  
We can see that in the first stage, the infant stage, it's higher.  
Then, in the normal stage it continues to go down.  
Then, in the wear-out stage it goes up.  
And then, down again to 0.  
So, it is interesting to see how the failure density function changes over time in this example.  
And in many reliability analysis applications as well.  
In the bottom right plot, we have the cumulative failure function.  
Which increases over time.  
Going from 0 to 1.  
In the next video, we'll continue our discussion for non-repairable components.  
And I'll talk about the reliability modelling of such components.  
And in particular about the normal and weibull distributions.  
    
## 2.2.2 Reliability Modelling of Non-Repairable Components   
LECTURER:   
Welcome to the second video of section five.  
Building of the material we covered in the previous video.  
Here we are going to see how we can use normal and Weibull distributions to derive the probability and density function and hazard of failure rate of non repairable components.  
So let's start with the normal or Gaussian distribution.  
The pdf is given the equation 11 which is a two parameter function where mu is the mean and sigma is the standard deviation.  
So the pdf in question 11 is given by one over sigma times the square root of two times b times this exponential function.  
The cumulative probability function is given by equation 12 which is the integral of the probability and density function times du from minus infinity to x.  
Please note that the basic problem with normal distribution is that this integral can not be solved analytically.  
So basically there is not analytical solution to this integral.  
So very often we define the so called standard or standardised pdf.  
Which we define here as beta which is x minus mean over the standard deviation sigma.  
So the probability density function now becomes what we see in equation 13.  
Using the transformation we use z.  
We see that there is no mu or sigma so it basically becomes one over the square root of two times b times this exponential function where we now have only beta.  
No mu or sigma.  
And we have probability tables for this function which (INAUDIBLE) This is how we study the probability a normalise pdf.  
Now because this integral can not be solved analytically we'll go through together some states numerical calculations for solving this integral for standard pdf.  
You do not need to know this expressions.  
These are only provided here to demonstrate the procedure.  
So let's assume we need to calculate the probability qz where z is larger than zero for given z.  
Qz is given by one which is the pdf times the term in the bracket.  
So we have y, b's and t's.  
As we said y is equal to the pdf which we saw in equation 13.  
where z is considered to be known.  
Let's also assume that the parameter t is given by this expression which is equal to one over one plus r times z.  
R is given here and the b parameters are also given.  
So to summarise we know b1, b2, b3, b4 and b5.  
And t is also given for which we also know r.  
So we are in position to calculate the probability qz for a given z which is the independent variable for which we want to calculate, specify its probability.  
The pdf y in the qz equation at the top is also given which is an expression of z only.  
So to calculate the probability qz.  
Now, in normal distribution we may have the inverse problem note the first approach (INAUDIBLE) before for given z to calculate qz.  
But for a given qz to calculate z.  
So for given probability to calculate the standardise independent variable z.  
And the expressions are given here.  
So we start from the end, the variable c and d are given here.  
The expression t is also given.  
So if we replace c, d and t in the expression of z we can get z.  
The hazard failure function is what we are interested in.  
We have to do numerical calculations from equation seven we saw the previous video where the failure rate is given by the ratio of the failure density function ft and the reliability function rt.  
So we get the curve we see in this figure.  
The failure function is (INAUDIBLE) increasing as a function of x.  
That is exactly what we need for the wear out stage.  
There is a value of x where x is equal to mu for which lambda x is equal to 0.798 over sigma.  
So in practise normal distribution is not often used due to mainly this numerical calculations we just saw.  
Weibull distribution which we'll see next is more often used but it really depends on application and the purpose of your study.  
Before we talk about Weibull distribution let's see an example about normal distribution.  
Let's consider that the Lightning Department of a city installed 2000 electric lamps which have an average life of 1000 burning hours with a standard deviation of 200 hours.  
We are interested to calculate how many lambs might be expected to fail in the first 700 hours.  
So for the problem we are given that mu is equal to 2000 hours and the standard deviation sigma is 200 hours.  
We can calculate z from the numerical equation that 13 we saw area as 700 the (INAUDIBLE) time minus 1000 the average life over the standard deviation 200 hours and we get z equal to minus 1.5.  
Next from equation 14 we have qz is equal to q-z.  
We just calculated equal to 0.0668.  
Then to get the expected number of failures we'll calculate this probability using the total number of electric lamps 2000.  
So we'll have 2000 times 0.0668 we get 133.6 which is rounded up to 134.  
Now let's see the second question after a what period of burning hours what we expect 10% of lamps to have failed.  
This is the inverse problem.  
We know that 10% of lamps will fail and we are looking for the amount of burning hours.  
So we know now that the probability q is 0.1.  
from equation 15 we get that z equal to minus 1.2817.  
So using the inverse transform x minus 1000.  
The average life of the lamps over 200 the standard deviation sigma is equal to minus 1.2817 which in turn gives x equal to 743.7 hours.  
Rounding this up to 744 hours.  
So this is a quite good example to understand how normal distribution works given different (INAUDIBLE) and applications.  
Since we covered the normal distribution and (INAUDIBLE) example let's now move on to Weibull distribution.  
The most widely used distribution for non repairable components or systems.  
The probability of failure density function is given by equation 16 where t beta and alpha are considered larger than zero.  
So the pdf in Weibull distribution is given by the ratio beta times t in the power of betaminus one over alpha in the power of beta time exponential function of the negative ratio t over alpha in the power of beta.  
The cumulative probability function or (INAUDIBLE) is given by equation 17 which is equal to one minus exponential function of the negative ratio t over alpha in the power of beta.  
The hazard failure rate is a very nice analytical expression.  
In contrast to the normal distribution where we said that analytical calculations are very difficult.  
In Weibull distribution it has a failure function is given by the ratio of the failure density function ft over the reliability function rt which gives us the ratio beta times t in the power of beta minus one over alpha in the power of beta.  
So for different values of beta we get different shapes of lambda t.  
This is why beta can be considered like a shaping variable.  
If beta is smaller than one we get a decreasing failure rate as we see in this figure in this slide.  
So this shape of failure rate can be used in the infant stage of the bathtub curve we discussed on the previous video.  
If beta is equal to one the we get a constant failure rate which refers to the normal life stage of the bathtub curve.  
Then finally if we consider that beta is larger than one we get a monotonically increasing failure rate which we refer to the wear out stage of the bathtub curve.  
So we see that by varying the value of beta we can describe the whole bathtub curve or all the three stages.  
Or you also have analytical solutions.  
And this is the (INAUDIBLE) of the Weibull distribution.  
And this is why the Weibull distribution is the most widely used probability distribution function.  
We'll close this video with a brief algorithm for practical implementation with regards to non repairable components.  
Before we move on to the next video to repairable components.  
Our objective is to predict possible failure of a component and decide on component replacement.  
So we are interested to see whether the component would fail and evaluate if we need to replace this component.  
So the algorithm, the reliability part of this procedure is as follows.  
The first step is to gather the failure data which is something like the table we saw in example one in the previous video.  
Then we need to select a proper probability distribution model.  
Next we need to determine the optimal best fitted parameters of the distribution models for example mu and sigma for normal distribution.  
There are two main techniques to do this the least square estimator and the maximum likelihood estimator, MLE.  
The next step is to carry out the goodness of the fit test to validate the presumed distribution model basically to see if the chosen distribution model in step two really describes the data well.  
And again there are different tests we can run here such as the Kolmogorov Smirnov test.  
If we don't get satisfactory results we return to step two, select a different probability distribution model and repeat the whole procedure until satisfactory accuracy is obtained.  
So in this video we covered the normal and Weibull distributions and their benefits and drawbacks for different applications, along with an illustrated example and this practically (INAUDIBLE) procedure.  
In the next video we'll start talking about repairable components.  
Starting again with some fundamental concepts before we move on to more complicated applications.  
    
# 2.3 Fundamentals of Repairable Components   
LECTURER:   
Welcome to the third video of section five.  
In this video we'll start with discussions for repairable components.  
As with the non repairable components we'll start with some fundamentals before we move on to more advanced concepts.  
Let's start with the basic model of repairable systems.  
When we are talking about non repairable components a component will be up, will be functional until it fails and remains down as it can not be repaired.  
In contrast a repairable system or component can be in two states the up and down states since it can be repaired.  
We see this in the top figure in this slide.  
So along the life cycle of a component, a component can either be in the up or down state with times T up and T sown respectively.  
So we have two random variables now, the up time and the down time which will consider they both have an explanation distribution function.  
We will also assume that then hazard rate lambda T is constant.  
So the cumulative and reliability function Qt is given by one minus E in the power of minus lambda T.  
And the failure of probability distribution function Ft is given by lambda times E in the power of minus lambda T.  
So far this is repetition of what we saw for non repairable components.  
Here in the repairable components we will expressions of equation 19 in the state space representation.  
It is called state based because as we saw the repairable components can be in two states the up and down.  
As we see in the figure in the bottom of this slide a component can be in service or it can be in a fail state.  
We model the transition from the up and down state using the failure hazard rate lambda.  
And the transition from the down to up state using the mean rate which is called repair rate.  
Let's see now how we can use this failure and repair rate to define the probabilities of transition between the up and down states.  
The probability to leave state one in time dt is lambda times dt see equation six how we can derive this.  
And to leave state two is mu times dt.  
Now the probability of being in the up state, state one in t+dt is equal to the expression we see here which is the probability that we did not leave state one in dt.  
Which is given by one minus lambda times dt times p1 t.  
And the probability of leaving state two meaning it wasn't state two that was repaired in dt which is equal to mu the repair rate times dt times p2 t.  
Similarly the probability of being in state two is the sum of the probabilities of being in the down state and does not leave it which is given by one minus mu times dt times p2t and the probability of leaving state one.  
Meaning it was state one that left state one due to failure in dt which is given by the product of lambda times dt times p1t.  
Let's now see how we can solve the differential equations in 20 using the so called stochastic processes Markov model.  
The probabilities p1t and p2t change as we see in this figure.  
If the initial condition is that the component was up p1t changes over time as we see in this figure.  
Basically converging to specific value.  
Similarly if the component was in the down state p2t convert just to specific value too.  
Reliability analysis is based on steady state probabilities.  
No transient processes are considered here.  
We basically have the steady state probabilities.  
Well we have the concepts of availability and unavailability.  
The availability p1 with time going to infinity is given by the ratio of mu over lambda plus mu.  
So repair rate over failures plus repair rate.  
The unavailability is given by the ratio of lambda over lambda plus mu.  
So the failure rate over failure plus repair rate.  
And these two values are the values that p1t and p2t are converging in the figure we see in this slide.  
Now let's talk about the concept of mean time to failure which refers to the physical meaning of lambda if you like.  
We saw in equation 10 the mean time to failure for a non repairable component.  
In equation 22 we'll have the mean time to failure for repairable components which is the integral of p1t times pt in the integral from zero to infinity which gives us one over the lambda, one over failure rate.  
Similarly mean time to repair is given by equation 23.  
When we have the integral from zero to infinity of p2t times dt which gives us one over mu.  
One over the repair rate.  
Having defined the mean time to failure and the mean time to repair we can characterise the average behaviour of a component meaning averaging over time.  
Now the availability A is given by the mean time to failure mu over meantime to failure plus mean time to repair.  
And the unavailability U is given by the mean time to repair over mean time to failure plus mean time to repair.  
So we see from this figure the component is switched between the up and down state using the mean time to failure and mean time to repair, to define the up and down times during the cycle.  
This is an average process as we always have r and m in the down and up stairs respectively.  
So basically what we did here was to derive from completely stochastic process using Markov modelling.  
The calculation of the steady state probabilities and durations where component can be in the up or down state.  
Which again in this example it is average over time.  
It is also worth noting that in some occasions you may come across the mean time between failures which looking at this example here is given by m.  
Basically it is the same with the mean time to failure for repairable components.  
Let's see now a small example to understand better this concepts.  
Let's assume that the power system component has a constant failure rate of 0.001 per hour and a constant repair rate of 0.02 1/h.  
We want to calculate the steady state reliability indices.  
The solution is as follows.  
We saw from equation 22 that the mean time to failure m is one over lambda which gives us one over 0.001 that is equal to 1000 hours.  
Similarly from equation 23 the mean time to repair r is one over the repair rate.  
So one over 0.02 which is equal to 50 hours.  
The availability A is given by the ratio of mean time to failure m over mean time to repair plus mean time to failure so.  
It is equal to 1,000 over 1,000 plus 50 which is equal to 0.9524.  
The unavailability u is given by the ratio of meantime to repair r over r plus m which is 50 over a 1,050 giving 0.0476.  
The cycle which composed by r plus m is equal to 1,050 hours.  
And the frequency is equal to one over t which is equal to what we see here.  
Importantly, we also calculate another reliability index, the so called expected yearly outage duration which is given by the product of unavailability and 8,760 the hours within a year since we're interested for a yearly outage which gives 416.98 hours.  
So far we covered the concepts for individual components.  
So now we'll expand these discussions to multiple components to a system of n components.  
Each component in this system can be either in the up and down state.  
So if the system is composed of two components, the system would have four states, to in the power of two.  
If it has three components, the system would have a states, two in the power of three and so on.  
Will be using state base representation which we will discuss now.  
We see in this slide a state -space diagram which as discussed each state has an unknown probability.  
And the transitions between states are the fail and repair rates.  
The frequency or failure density of a single component of leaving state one is equal to the frequency of entering state two which we would express in question 24.  
Basically, the product of availability times the transition rate which is the failure rate is equal to the product of unavailability times the repair rate which is turn equal to lambda times mu over lambda plus mu.  
We have this general methodology which we use and demonstrate in an example in the next couple of slides.  
First, we need to write the balance of frequencies for each state from one to end where we consider that the failure and repair rates entering a state are positive while those leaving a state are negative.  
The second state is to derive the system matrix.  
And finally solve this system of linear algebraic equations.  
Let's now see the example.  
There are two components with two states.  
So there are important four states two in the power of two.  
In general, for a system of a components with two states each, we'll have two in the power of n states.  
In this example, in state one both components are in service, while in state two, component one has failed and component two is up.  
The transition from state one to state two is lambda one.  
The failure rate of component one...  
The transition of state two back to state one is the repair rate of component one.  
Similarly, we have state three where component one is up and component two is down.  
With the transition from state one to state three being given by lambda two, and the transition from state three to state one being given by the repair rate of component two.  
Finally, we have state four where both components are down with the corresponding transition rates from states two and three respectively.  
Let's see how we can solve this problem.  
We have four states whose probabilities p1, p2, p3 and p4 are unknown.  
We can derive the following steady - state equations.  
Again, as a reminder, what leaves a state is negative and what enters a state is positive.  
In the first equation, referring to state one, we have minus lambda one and lambda two times p1 negative because they are leaving to state one plus mu1 times p2 plus mu 2 times p3, both positive as they enter state one and all together equal to zero.  
Similarly for the second equation, we have lambda one times p1 positive as is entering state two, minus mu1 plus lambda two times p2 negative because it is leaving state two, plus mu2 times p4 positive as it is entering state two.  
And again all this equal to zero.  
Following the same thinking, we can derive the following two equations for state three and state four respectively.  
We also have a fifth equation condition where the sum of all the state probabilities p1, p2, p3 and p4 should be equal to one.  
So we have four unknown variables with five equations which will try to solve.  
Our solution is given with these equations which are basically products of individual availabilities and unavailabilities.  
For example, the probability of state one where both components are up is given by the product of the availability of the two components.  
The probability of state two where component one has failed and component two is in series is given by the product of the unavailability of component one and the availability of component two and so on for p3 and p4.  
So we see that we can express the probability of each state using availability and unavailability of the components given their state.  
Now, we may have two possible connections of the two individual components.  
They may be connected in series or they may be connected in parallel.  
If we assume a series connection of the two components, for example a transformer and a cable, then the availability of this system is equal to p1 meaning both components should be in series.  
And the unavailability is one minus the availability or in other words one minus the sum of p2, p3 and p4.  
However, if the components are connected in parallel, then it is easy to ask a different question, when is this system unavailable? The answer is when both components are unavailable meaning state four.  
So there unavailability is equal to the probability of state four while the availability is obviously equal to one minus the unavailability.  
So concluding and summarising in this video we've covered the fundamentals to repair components, defining the concepts of availability and unavailability using the failure and repair rates of individual components.  
We saw how to derive the meantime to failure, a meantime to repair using the failure repair rates, and we discuss how we can derive the steady - state probabilities of systems composed of n components along with two illustrative examples.  
In the next video, we will go into more detail on steady - state reliability modelling of systems.  
    
# 2.4 Reliability Techniques for Modelling Non-Repairable and Repairable Components   
## 2.4.1 Steady State Reliability Modelling of Systems   
LECTURER:   
Welcome to the fourth video of section five called 'Steady State Reliability Modelling of Systems'.  
Where we're going to see some general expressions about steady state probabilities.  
Talk about common mode failures.  
And see into more detail how in conserved series and parallel systems As we saw an example four in the previous video, the frequencies of leaving a state and entering a state are equal.  
So, in the left hand side in equation 25, we'll have the frequency of leaving a state, and in the right hand side the frequency of entering a state.  
Please note that akk and aki, refer to failure rates and P refer to probabilities.  
So in equation 25 we'll have on the left hand side, minus because it is leaving a state.  
The failure rate akk times the probability Pk of estate k and in the right hand side, we'll have the sum of the products of failure rates times the probabilities of the components one to n.  
The expected time residing at state k in equation 26 is equal to the mean time to failure which is in turn equal to one of over lambda k, Where lambda k is the rate of leaving state k, or one over minus akk.  
The frequency of leaving a state is equal to the product of lambda k and Pk in equation 27, while the duration of cycle at state k, is one over fk.  
Which is equal to mk plus rk, where rk here, is the expected time residing outside state k.  
For n states, please note that the system of n linear algebraic equations needs to be solved, which can be done numerically.  
Now let's see a bit more complex example of common mode failures, which is a more realistic example.  
Consider that you have two overhead lines on the same right of way, or two circuits on the same tower.  
Which is the case with the majority of transmission lines in the UK.  
This category of failures, the common mode failures, are particularly critical to consider in many real life occasions.  
For example, when there is a windstorm or a snowstorm or in general an extreme weather event or a natural hazard.  
It is very possible to have a simultaneous outage of two or more components due to a common cause.  
In such occasions we talk about the common mode failure rate lambda c.  
In the previous example.  
Component, one could fail completely independently from component two, for different causes.  
The state space diagram for common mode failures is shown in this figure.  
Then difference with a state space diagram we discussed in the previous video, where each component could fail independently.  
Is the direct transition from state one to state four with the transitional rate being equal to the common mode failure rate lambda c.  
So, we see in this state space diagram.  
That you to common cause it is possible to transit from stage one to stage four without being first in states two or four.  
However, please note that there is no transition back to state one from state four.  
Meaning that there is no simultaneous repair of both components.  
The transition from state four to state one, needs to be done through states two and three.  
Where component to component one will be repaired respectively.  
As before we have a full set of algebraic equations, representing the state space diagram, considering common mode failures.  
Providing the probabilities of being in each state p1, p2, p3 and p4, this is an approximate solution there real is quite complicated but it is accurate enough p1 is given by the product of a1 and a2 minus the probability of outage, due to common cause.  
Which is equal to the common mode failure lambda c, over mu1 plus mu2.  
p2 and p3 are the same as in the previous video, where we're looking at dependent components.  
But p4 changes here, as we need to consider the common mode failure.  
Now p4 becomes a product of unavailabilities of components one and two, plus the common mode failure rate lambda c, over mu1 plus mu2.  
Being positive now as it is entering state four.  
And similarly, the frequency of state four is given by the last equation, which is mu1 and mu2 times p4.  
Let's move on now to discuss series systems, where the components are connected series.  
As we see in this simple figure here.  
The aim is to find an equivalent component in terms of reliability probabilities, which we'll call s with failure rate s, and repair rate s For a series system of two components.  
The probability of the system being in the upstate is given by equation 29 here, which is equal to mu1 times mu2.  
The product of the repair rates of the two components, over the product of the sum of the corresponding failure and repair rates of the components.  
This gives us the ratio mu s, over lambda s, and mu s.  
We don't know at the moment lambda s and mu s So, we need to find them.  
The transition rate from the system upstate is equal to the sum of the failure rates of the two components.  
So basically this means if either of the two components fail.  
The system will fail. By replacing equation 30 and equation 29, and noting that the repair rate is the reciprocal of the average repair time. We get the expression in equation 31.  
So, we have the repair time of the system rs, is equal to one over mu s, which can be elaborated in the expression we see here.  
And we finally get the approximate expression of lambda one times r1 plus lambda two times r2 over lambda s.  
Even generalize these expressions, to a system of n series components.  
The failure rate of the system lambda s, will be simply equal to the sum of the individual component failure rates as any component failure will result in the system failure.  
Since the components are connected in series.  
The repair time of the system, will be equal to the sum of the products of the failure and repair times of components lambda i and ri, over the failure rate of the system lambda s.  
Finally, the unavailability will be equal to the product of the failure rate and repair time of the system.  
Or equally, the sum of the products of the failure rates, and repair times of the components.  
These expression apply for distribution networks, which are radial, meaning the components are connected mainly in series.  
The situation is a bit different and more complicated when the components are connected in parallel as we see in this simple figure here.  
Again we'll try to find an equivalent component s, in terms of reliability probabilities with a failure rate lambda p and repair rate mu p.  
In contrast with the series connection.  
In order to get assisted failure, the system being down.  
We need a simultaneous failure of both components one and two.  
Basically as we have seen in the previous video.  
The only unavailability state, is state four where both components are out.  
Here, we have the probability of being down equation 33, equal to the product of their individual failure rates lambda one and lambda two, over the product of the sums of the individual failure and repair rates of the components.  
Which can be simplified to mu p, the repair rate of the system.  
Over the sum of the failure to repair rate of the system.  
The rate of transition from down state is mu1 plus mu2 which is equivalent to mu p.  
Using the expression for the parallel connection, we get the equation 34.  
Which says that rp is equal to r1 times r2 over the sum of r1 and r2.  
Substituting equation 34 to equation 33 we get this expression for lambda p.  
In the denominator, one is much bigger than the last two terms.  
So lambda p can be approximated to lambda one times lambda two times the sum of r1 and r2.  
Finally the unavailability of the system U p, is given by the product lambda p and rp which is equal to the product of lambda one, lambda two, r1 and r2.  
If we extend this to three components, it gets more complicated.  
The corresponding expressions are given here in equation 36, where we ultimately get the unavailability of a system with three party components, being equal to the product of lambda one, lambda two, lambda three, r1, r2 and r3.  
It is very critical to understand both this concept expressions and how we derive expressions for both series and parallel systems as they are very useful for simplifying systems with a series parallel structure.  
Let's now go through an example.  
To understand these concepts better.  
The failure rates of three series components are 0.05, 0.01 and 0.02 respectively.  
And they are repair times are 2015 and 25 hours respectively.  
We want to calculate the system failure rate, average repair time, and unavailability of the system.  
We saw before, that when the components are connected in series, the failure rate of the system is the sum of the individual component failure rates as if any of the components will fail the system would fail.  
So, lambda s, the failure rate of the system, is equal to 0.05, plus 0.01, plus 0.02, which gives us 0.08 failures per year.  
The unavailability is the sum of failure rate, times the repair time of each component.  
So we have 0.05 times 20, plus 0.01 times 15, plus 0.02 times 25, which gives us 1.65 hours per year.  
Finally, the repair time of the system is equal to the ratio of the system unavailability 1.65 and the failure rate of the system, 0.08 which gives us 20.6 hours.  
Please note the units for the failure rate, repair time and unavailability.  
We have failures per year, hours, and hours per year respectively.  
Now, let's see an example of two parallel components, with failure rates 0.05 and 0.02 failures per year.  
And repair times of 20 and 25 hours respectively.  
Again, we want to calculate the system failure rate, average repair time and unavailability.  
Using the expressions we defined in the previous slide, the failure rate of the system is given by the product of the individual failure rate, times the sum of individual repair times.  
Please pay attention, that here we're using the equation we saw before, but divided by 8,760 as r1 and r2 are given in hours, 20 and 25 hours respectively.  
So we need to divide by 8,760 to get the failure rate per year.  
So there is all this 5.14 times ten in the power of minus six failures per year.  
The repair time is given by the expression we defined before, which gives us 11.1 hours.  
And similarly, the system unavailability is equal to 5.71 times ten in the power of minus five hours per year.  
Let's see now another example a bit more complicated as it has a series parallel system.  
We want to calculate again the reliability indices.  
Unavailability, availability, failure rate and average repair time r.  
So, the solution is as follows.  
First we need to make a new component six.  
From the series components three four and five.  
We have the equations to get this equivalent new component six.  
Then we'll have to get a new equivalent component seven from the parallel connection of components two and six.  
Again we have the equations to do so.  
And finally using the new components seven we'll have a series connection of component one and seven.  
So the problem is simplified to a simple series connection of components one and seven.  
Please try yourself to solve this problem with assumed numbers similar to the previous example.  
So, in this video. We went into more details of how to analyse from a reliability, probability perspective, series and parallel systems.  
And we have also talked about the critical concept of common mode failures, which are very frequent in the real world applications.  
In the next video, we will talk about minimum (INAUDIBLE) and (INAUDIBLE) methods, which are very important applications in reliability studies of both repairable and non-repairable components.  
    
## 2.4.2 Minimal Tie Sets and Cut Sets Methods   
LECTURER:   
Welcome to the fifth video of section five, where we talk about the techniques of minimal tie sets and cut sets and demonstrate their application in reliability studies of both non-repairable and repairable components.  
Let's start with the minimal tie sets.  
To begin with, the path is a set of components that forms a connection between input and output.  
A minimal path is one in which no node is traversed more than once.  
We'll see later on how to define this minimal paths.  
We'll use for demonstration purposes the so called bridge network, which cannot be solved using expressions, equivalents and so on that we saw so far.  
So let's start looking in multeity, the i-th minimal path is denoted by Ti, with 'i' from 1 to n.  
System reliability is given by the expression in equation 37, where 'P' is the probability and 'U' denotes union, meaning the logical or operation.  
Please note that all minimal paths are connected in parallel.  
Let's see this calculations for the bridge network that we can see in this figure.  
In this network, we have the source in the left and the load point at the right, with some components connected in between the source and the load point.  
From a visual inspection of this network, we can define four minimal paths.  
T1 path 1 is the path include the components 1 and 4.  
T2 includes components 2 and 5.  
T3 includes components 1, 3 and 5.  
And T4 path 4 includes components 2, 3 and 4.  
So we have a parallel connection of the four minimal paths, T1, T2, T3 and T4.  
So the minimal paths are not independent because one component is in several paths, which makes the solution of this network from a reliability point of view, more complicated of the simple networks we saw so far in the previous videos.  
So in this bridge network, the reliability of the system is given by the probability of minimum path 1 union minimum path 2, union minimum path 3, union minimum path 4.  
If the minimum paths were independent, this could be just the sum of the probabilities of each minimum path, but there are not independent.  
Let's see how we can solve this.  
If R(Ti) is the probability that the tie set 'i' is reliable, then we get this long expression for Rs.  
So we have the sum of first-order terms, basically, the reliability of each path 1 to 4.  
Then we have to subtract the intersections of two minimal paths which are still combinations.  
Then we have to add all combinations of intersections of three minimal paths where there are four of them.  
And finally, we subtract the intersection of all four minimal paths.  
So this is getting a bit more complicated of what we covered so far.  
In other to prove equation 39, try to draw three sets which intersect each other and find their union.  
Let's see an example now.  
For the given network below, we want to find minimal paths and write the expression for reliability s and calculate reliability s if the reliability of each component is 0.95.  
In this example, reliability means that all the load points are supplied So the first minimal path is 1, 2, 4, and 5.  
Basically, consider that component 3 failed, but all the points are supplied.  
The second minimal path is 1, 3, 4 and 5, where we'll consider that component 2 failed.  
The third minimal path is 1, 2, 3 and 4, with component 5 failed.  
The final one is components 1, 2, 3 and 5, with component 4 failing.  
Finally, the reliability of the system is the probability of T1 union T2 union T3 union T4.  
And then using the expression in equation 39, we can express and calculate Rs, which you can do home to practise this example.  
So we discussed in the previous slides what the minimal tie set is.  
Let's see now what the minimal cut set is.  
A cut is basically, a line that disconnects the inputs from the outputs.  
Hence, a cut set is a set of elements that, if it fails, it will cause the system to fail.  
Similarly with the minimum tie set, a minimum cut set is one in which there is no proper subset of elements whose failure alone would cause the system to fail.  
We have similar expressions with the ones for minimal tie sets, but it is easier here to begin with defining the system unavailability.  
So the i-th minimum cut set is now denoted with Ci with 'i' ranging from 1 to n.  
The system unavailability is defined by equation 40, which is basically, the probability of the union of the minimum cut sets.  
So basically, if any of the minimal cut sets occur, then the system will fail, will become unavailable.  
The reliability of the system in equation 41, is then defined as 1 minus the unavailability from equation 40.  
Note that we have the same complexity as before, meaning that the minimum cut sets are again not independent.  
So, equation 40 is expanded in a similar way we saw before in equation 39.  
In this case though, all minimal cut sets are connected in series and not in parallel as in the minimum tie sets because each one leads to the system failure.  
Basically, as aforementioned, if any of the minimum cut sets occur, then the other system will fail.  
Let's see an example to understand this better.  
For the system given below, which is the same with the system we used for example 9, we need to find the minimum cut sets and the unavailability of the system.  
Starting with the minimum cut sets, we see that we have one cut set C1 that involves the figure of the very first component and cut sets where we have two components failing.  
So, C1 includes only component 1 considering that component 1 failed.  
In minimum cut set 2, C2, we have components 2 and 3 failing, meaning that the input is completely separated from the output which are the loads of 3, 4 and 5.  
Minimal cut set 3, C3, refers to the failure of components 2 and 4.  
C4 refers to the failure of components 2, 5 and so on for C5, C6 and C7.  
So, there are seven minimal cuts for this example.  
Given the large number of minimal cut sets, the expression of system unavailability gets quite complicated.  
We basically have to go up to the product of seven events.  
The first part is the sum of the unavailability of each cut set from 1 to 7.  
Then we have to subtract the unavailability of the intersection of two cuts, denote the intersections of three cuts, and so on which gives us a very long expression.  
Fortunately, power systems are highly reliable systems.  
So here we made approximation of using only the first-order terms which gives us the expression of equation 43, where we basically have only the sum of the unavailability of the minimal cut sets, 1 to 7.  
Now, let's solve the bridge problem using the last method we'll see in this video, the Bayes' theorem.  
So, this method is based on the so called total probability theory.  
Let's first consider an event A which depends on mutual exclusive independent events B1, B2 and so on.  
Then the probability of this main event A is expressed in equation 43 which is the sum of conditional probabilities because B1, B2 and so on are mutually exclusive.  
The Bayes' theorem can be then applied to system reliability Rs as follows, the reliability Rs is equal to the probability that the system is in success state if one component i is up and then we multiply with the reliability of component i.  
Then we have to add the second conditional probability which refers to the probability that the system is in success state if the component i is down, times the unavailability of component i.  
Let's see how we can solve the bridge network using this theorem.  
If we assume that component 3 is reliable, we can replace component 3 with a line in the bridge network as we see in the left hand side figure.  
So we can now apply the concept we saw for parallel components.  
Basically, component 1 is in parallel with component 2 and component 4 is in parallel with component 5.  
If on the other hand component 3 failed, we completely remove this line from the network as in the right hand side figure.  
So, we now have component 1 in series with component 4 and component 2 in series with component 5.  
And the twin series systems are in parallel.  
Finally, the expression for the reliability of the system is given by this equation where we have two terms for the conditional component 3 is healthy, fully reliable or failed.  
So we see that the Bayes' theorem can be particularly useful in some applications.  
We'll close section five with the following video which is the last one for this section talking about fault tree analysis, which is an efficient way of representing in a graphical way the events or combination of events that can lead to a system failure, making this technique widely used in reliability studies.  
    
## 2.4.3 Fault Tree Analysis   
LECTURER:   
In the last video of section five, we'll talk about fault tree analysis which is a well established and widely used reliability analysis technique.  
So let's start with some basic definitions.  
A fault tree is a graphical representation of events, causes and consequences, that lead to a failure of the considered system function.  
Due to this graphical representation which provides a nice visualisation of the path leading to the failure of the system, it is very widely used.  
For example, fault tree analysis is very frequently used in protection system reliability modelling.  
I have personally used fault tree analysis extensively in my research for example, where I wanted to evaluate the reliability of wide area protection schemes for national grid.  
I have found this technique very efficient as it enables identification of those events or combination of events that can lead to the failure of a protection scheme and you can also include in the fault tree all types of components for example control, communication, actuators and so on.  
In fault tree analysis, the events that lead to the system failure need to be determined and also we need to find their mutual logical connectivity.  
This analysis is continued until basic events are identified which usually refer to the failure of the individual components.  
The procedure to build a fault tree is to start from the top event then find the events that cause this top event, their mutual connectivity and so on.  
So, we are talking here about a top-down approach.  
The logical symbols, most frequently used to describe the logical connectivity of the events are shown here, which include the AND gate, which means the output will occur if all the input events will occur.  
The OR gate where the output will occur if any of the inputs will occur and the condition symbol, where the output will occur if the input occurs but under a specific condition.  
We can also see here the event symbols.  
One will have the basic event, the output event and the event condition.  
We'll see an example in the next slide to understand how to use these symbols as well as the logical symbols.  
In our example, we want to construct the fault tree for the power system given below.  
We see the consumer 'C' is connected to busbar 'S'.  
We...sorry let's go back from (COUGHS) we see here.  
We see the consumer 'C' is connected to busbar 'S' who is supplied from power station 'E' via lines L1 and L2.  
A local generator 'G' is also connected to busbar 'S' via circuit breaker 'B'.  
Let's see how we can solve this using fault tree analysis.  
The output event is the interruption of supply to customer 'C'.  
The first event 'X' which can result in supply interruption, is the simultaneous failure of local generator 'G' and busbar 'S'.  
The event 'Z' will be the failure of generator 'G' and failure of breaker 'B' and event 'V' will be the simultaneous failure of both lines 1 and 2.  
The last event will be the simultaneous failure for which we are using the symbol underscore of all the components.  
Busbar 'S', power station 'E', generator 'G', breaker 'B' and lines L1 and L2.  
So, let's see the fault tree.  
We start with the top event, which is supply interruption to point 'C'.  
This can happen when one of three events can happen.  
So we use the OR gate to connect these three events to the top event.  
The first event is event 'X' where under the event 'X', we have the AND gate to represent the simultaneous failure of generator 'G' and busbar 'S'.  
The system supplying busbar 'S' failure, can occur under two events.  
Either failure of generator 'E' or simultaneous failure of lines L1 and L2.  
We represent this simultaneous failure of lines L1 and L2 using an AND gate.  
The second event is 'Z' where is the failure of the local generator under the condition the circuit breaker also fails.  
If both generator and circuit breaker fail, then there is no busbar protection to clear the fault and the fault will spread.  
So, we'll have an interruption in the power supply to point 'C'.  
The third event is simply the failure of busbar 'S' which will result in the total power supply interruption to point 'C'.  
So in fault tree analysis, the system unavailability is calculated from the fault tree while the general expression for mutually dependent events needs to be used.  
The probability that at least one of the events 'Di', with 'i' ranging from 1 to m, is going to occur, where we basically use the logical gate OR, is as follows.  
First, we have the first order probabilities, then we subtract the second order probabilities, add the third order probabilities and so on.  
Next, the probability that all events will occur, which is represented with the logical AND gate, is as in equation 46 where we now have to use conditional probabilities as the events are mutually dependent.  
So, in the previous example we can express the following equations.  
Here we need to consider the mutual dependencies between the events we have in the fault tree.  
For example, X and Y events are dependent.  
Please take the time to understand how we came up with these equations, and raise any questions or problems you may face in doing so.  
The last point to mention here is that we can develop the minimum cuts that we discussed in the previous video from the fault trees quite easily.  
And that is because as a fault tree is a graphical representation of the events or combination of events leading to the top event, it is closely followed to identify the cuts or the paths leading to the failure of the system.  
    
# 2.5 Introduction to Reliability of Generation and Complex Systems   
LECTURER:   
Welcome to section six, called Reliability of Generation and Complex Systems.  
In the first video of this section, called reliability modelling of generating units, we'll discuss the state modelling of generating units, and how to calculate the availability and unavailability of generating units.  
In the second video called generation capacity states in a system, we'll see how we can construct capacity outage tables of systems consisting of many generating units.  
And how we'll deal with systems that have identical capacities states in order to reduce the complexity of the problem.  
In the third video called reliability indices for generation load systems, we'll see the approach for calculating key liability indices of such systems, which are very critical and drive basically the planning and operation of these systems.  
The forth video generation expansion and operation planning, we'll show how these reliability indices can be used to inform the generation capacity expansion planning as well as the operating reserves planning in a system.  
The fifth and last video of this section will cover a very important application approach in reliability analysis studies.  
Monte Carlo Simulation which is widely used particularly in complex systems, where there is a large number of components with multiple states, resulting in a large number of overall system states.  
    
# 2.6 Reliability of Generation Systems   
## 2.6.1 Reliability Modelling of Generating Units   
LECTURER:   
So having covered the reliability modelling of a component, looking at the states base representation, meantime to failure, availability, unavailability and so on, in section five, let's look now at the reliability modelling on generating units.  
When we're talking about the generating unit, we have the basic two state model we see in this figure.  
When we can define state one, unit at full capacity and state two unit failed where we have zero output.  
The transition rates between these two states are given again by the failure rate lambda and repair rate mu.  
Then availability of generating unit based on these two state model is given by the first equation we see here which is also referred to as force outage rate in many textbooks where the unavailability is given by the ratio or the failure rate over the sum of fail and repair rate.  
Just a reminder that the meantime to failure m is equal to one over lambda the failure rate and meantime to repair r is equal to one over mean the repair rate.  
So this is in turn equal to the ratio of the sum of downtimes over the sums of the downtimes and uptimes.  
Similarly, the availability is given by the second equation which is equal to the repair rate over the sum of the failure and repair rates which is in turn equal to the sum of the uptimes over the sums of the downtimes and uptimes.  
The total cycle is equal to the sum of m and r, the meantime to failure and meantime to repair.  
So their frequency is again equal to one over the total cycle where we get the product of the failure rate lambda and availability or equal to repair rate mean and unavailability.  
And here under to the questions, we have again all the quantities we saw in section five just to refresh your memory.  
However, in real world applications, it is possible that the generating unit operates at a derated state.  
And derated state is the state where the generating unit can produce only part of it's nominal output.  
For example 50% or 75% due to different constraints.  
These two state model does not accommodate this third or multiple derated states.  
And this is the reason why we expand these two state model to the three state model we have in this figure here.  
So basically, we have three states of generating unit.  
State one is the up state.  
State two is the down state.  
And state three is the derated state.  
And we have several transition rates between these states.  
We have lambda and mu between the up and down states.  
But we also have other failure and repair rates between the up state and the derated state.  
And similarly from the down to and from the derated state.  
So we can see that all the transition are possible.  
This model requires writing up three state equations which we can use afterwards to calculate the probabilities of the three states.  
If we have two derated states would then have to define four state equations which we need to solve and so on.  
However, in practice we often use a simplified approach which means we use an equivalent two state model.  
The idea is to calculate the equivalent time with full output and the equivalent time with zero output.  
So let's first calculate the equivalent time with full output which is equal to the original uptime plus the submission k of all the derated states where we have n minus one states.  
Then we multiply the duration of each derated state k, tk with the ration of the derated capacity over the full capacity.  
Similarly with the downtime, we have the original downtime plus the submission k of all the derated states where we have the product of each derated state k, pk times the difference between the full and derated output over the nominal full output.  
So let's see now we can define the availability and unavailability using this expression's equations.  
The equivalent availability is given by the uptime we defined in the previous slide over the sum of the total up and downtimes.  
The equivalent unavailability is given by the downtime we defined in the previous slide over the sum of the total up and downtimes.  
It is also possible to define equivalent failure and repair rates but we're not going to do this here as these expressions are sufficient for our purposes.  
Let's see an example now.  
A 500 MW unit has a derated state of 300 MW.  
Full 500 MW, derated 300 MW and zero capacity times are 5,000 hours, 100 hours and 50 hours respectively.  
And we want to find the equivalent availability and unavailability.  
Using the equation we saw before with only one derated state, we get that the equivalent uptime is equal to 5,000 hours the full capacity time plus 100, the derated capacity time times the ratio of 300 MW the derated capacity over 500 MW the full capacity which gives us 5,060 hours.  
Similarly, we get the downtime with the second equation bearing in mind that we have only one derated state.  
And using the full derated capacities at respective times and we get 90 hours of equivalent downtime.  
The equivalent availability is given by the equation in this slide where we have 5,060 hours the equivalent total uptime over 5,060 plus 90 hours the equivalent downtime.  
This gives us unavailability of 0.9825.  
Following the question for the equivalent unavailability, we get 0.0175.  
So let's move on to see how we can model and simplify identical units.  
When we have n identical units in the system, the number of states is two in the power of n which can acquired big number of states.  
In this case, we need to group the identical units to reduce the number of states and make the reliability analysis more physical.  
So we aim to reduce the number of states from two in the power of n to n plus one states.  
So our basic approach is that the state space model is set and the states with the same probability are grouped.  
In the figure we see here, we can have all the units available state zero here, one fail unit state c1, two fail units state c2 and so on until state n where all the units are out.  
In this case the probability that k units are unavailable which is a simple binomial distribution is given by equation 48 here.  
We will see an example in the next slide to see how we can apply this equation to understand better.  
The failure rate the transition rate from a state k to a state k plus one is equal to n minus k times lambda.  
So for example if k is zero, the transition from state zero to state one is equal to the product of n and lambda.  
The transition rate back to state k minus one is equal to k times mu as we see in equation 49.  
If for example k where number of fail units is one then the transition rate is equal to mu.  
Finally, the available capacity in state k we have n minus k times that capacity in that state.  
Let's put some numbers now to this equations to get a better understanding.  
For a system of four identical 500 MW units with lambda equal to 0.4 per year, and mu equal to 9.6 one over year, we want to calculate the capacity outage probability table and equivalent state space diagram.  
Note that this is the first time we measure the capacity outage probability table which is a very important reliability indicator, when we have multiple generators.  
Let's first start with unavailability of a unit which is equal to 0.4/9.6+0.4, that gives us 0.04 and the availability is one minus the unavailability which gives 0.96.  
The state space diagram is given here, where we have four possible states.  
So the zero state is 200MW, next state is 150MW, then we get two units failing so we have 100MW in service, then in state three we have 50MW and finally we have all the units out in state four, so zero capacity in service.  
The transition rates between these states are given as in the state space diagram we had in the previous slide.  
So from state zero to state one, we have N which is 4 here times the failure rate 0.4, that gives us 1.6, and from state one to state zero we have the repair rate 9.6.  
From state one to state two we have N 4 minus 1 times lambda, so 3*0.4 that is 1.2, and from state two to state one, we have 2 times the repair rate, so 2*9.6 which gives us 19.2.  
And so on for the transition rates between the remaining states.  
I hope this is clear now, if not, try yourself to calculate all the state transition rates and raise any questions that you may have.  
So let's see now the capacity outage probability table.  
The probability that zero components are out of service, probability of state zero is equal 0.96 the availability of each unit in the power of 4 the number of units.  
In order to calculate the probability of being in state one, meaning one unit unavailable, we use equation 48.  
So we have four factorial, the number of units all over three factorial which we get by the difference of four the number of units and one, the number of failed units times one factorial as we have failed unit.  
Then we multiply this with the availability A in the power of n-k which is A in the power of 3, 0.96 in the power of 3, times the unavailability U in the power of the number of failed units 1, so we have just 0.04.  
This all together gives us a probability of state one equal 0.1415578.  
For the probability of being in state two, we have 4 factorial the number of units all over 2 factorial which we get by the difference of 4 the number of units and 2 the number of failed units in state 2 times 2 factorial as we now have 2 failed units.  
Then we multiply this with availability A in the power of n-k, which is A in the power of 2 here, so 0.96 in the power of 2 times the unavailability U in the power of the number of failed units 2, so we have 0.04 in the power of 2.  
This gives us the probability of being in state 2 which is equal to 0.0088474.  
And so on for calculating the probabilities of being in states 3 and 4.  
Try this yourself and please again, raise any problems you may face in doing so.  
We finally get the capacity outage probability table we see here, so basically there are five states n which is 4+1 states, so n the number of units plus one states, and please note that the sum of all the state probabilities, have to be one.  
If it is not one, then it means there is a mistake, so this is a very easy way to making sure that calculations are correct.  
Moving on to the peaking units now, in contrast to the base unit which covered the base load, peaking units are usually smaller units which cover the peak load so they have an intermittent operation.  
Secondly, because of this nature of operation, they can fail when they are not needed.  
So we have a four state model which is shown here, but the unavailability now is a conditioner probability, that the unit fails when it is needed.  
This is a major difference with the course that we've covered so far, which refer to mainly base units.  
So lets see the states now, starting from the in service state, state two.  
Let's define here D which is the average in service time per occasion of need, for example four hours during a day.  
So the transition rate from state two to state zero, the reserve shutdown is 1/D.  
If we now define (TUF) which is the average shutdown time between periods of need, then the transition between state zero and state two is 1-p.  
The probability of failure when starting the unit divided by (TUF) The transition rate between state zero and state three forced out in period of need, is p over (TUF) There is the standard transition between state two and three using the failure and repair rates.  
When the unit is in state three, it can go to a forced state, forced out but not needed, with the transition rate 1/D and the other way around transition from state one to state three, one over (TUF) Finally if the unit is not needed, then it can go from state one to state zero using the repair rate Mu.  
If we neglect the probability p, so p the starting failure probability equals zero, we get the following expression for unavailability where unavailability is equal to p3/p2+p3.  
So the unavailability is equal to the product of lambda and k, all over the sum of Mu and lambda times k.  
While the factor k is given by this expression here.  
Now, let's close this video with another example.  
A peaking unit has failure rate of 0.001 per hour and repair rate of 0.01 per hour.  
The peaking unit operates on average for D equals 10 hours when it is needed.  
We want to find the unit unavailability and availability for different shut-down times.  
So in this table, we assume different shut-down times in the first column, starting from zero hours up 100 hours.  
In the second column, we have the correction factor k, which we calculate using equation 51 where we know Mu and D and we assume (TUF) in the first column.  
So having calculated k, we now calculate the unavailability in the third column using again equation 51 for each assume shut-down time (TUF) In the last column, we have the availability which is one minus the unavailability.  
So we can clearly see that the longer the shutdown time (TUF) the smaller the unavailability, which is a logical conclusion.  
So in this video, we covered the two state model for generating unit and then we moved on and started the derated state, which is what happens in real world applications.  
We also saw how we can define and calculate equivalent up and down times, and availability and unavailability while considering derated states.  
Then we discussed the modelling of n identical units, like how to calculate the reliability indices of such a system.  
We close the video with discussions and calculations about peaking units which is very important to know as there are quite different concepts to consider compared to the base units.  
In the next video, we'll move on the generation capacity states in a system.  
    
## 2.6.2 Generation Capacity States in a System   
LECTURER:   
Welcome to the second video of section 6 called Generation Capacity States in a System.  
Having studied the generation models of a system in the previous video.  
We'll now move on in this video to talk about the generation load system.  
And we'll see how we can build a capacity outage table for such a system.  
It is important to begin this video by clarifying that when we are studying the generating capacity in a system.  
We talk about a one-point system.  
Basically, meaning we ignore the transmission network.  
And we gather the generation and load into one single node as shown in this simple figure.  
This is the so called generation and (INAUDIBLE) study in power systems.  
Where we basically consider only the generation load system.  
And we ignore the transmission network.  
Let's talk again about capacity outage probability tables.  
When we build a capacity outage table all units are independent and modelled with two-state models.  
Although the derated states can also be considered.  
So, the system will have many states.  
And we need the probability of each state which is given by the product of the individual unit availabilities and unavailabilities.  
And we'll see an example for this later.  
However, this requires a recursive algorithm for building a capacity outage table.  
In this algorithm, we are looking for the cumulative probability of a capacity outage state of X megawatts, P(X).  
After a unit of capacity C, megawatt.  
And unavailability of U is added.  
Please, note we consider now derated state here.  
The probability of a capacity outage state X is given by equation 52 here.  
Which is basically 1 minus U times the previous cumulative probability.  
That there was X megawatts in outage.  
Plus unavailability time previous cumulative probability.  
That was X megawatt minus C megawatt outage.  
We will see an example and application in the next slide to make this clear.  
If we want now to generalise this equation to units with derated states.  
Where we are now talking about multi-state modelling.  
We can use equation 53, we see here.  
Where n is the number of unit states.  
CA is the capacity of state A.  
And PA is the probability of state A.  
Please note that both equations 52 and 53 are based on convolution.  
Let's see now the example.  
A system consists of two 3MW units and one 5MW units whose FOR is 0.02.  
We want to construct a capacity outage table for this system.  
In the first state 0, all units are available.  
So, 0MW are out of service.  
Since all the units are independent.  
The state probability is given by the product of the individual availabilities of the units.  
Which is 1 minus the FOR outage rate.  
So, 1 minus 0.02.  
Which is 0.98.  
In the second state, we have 3MW out of service.  
Which can occur in case of an outage of any of the 3MW units.  
So, we have two possible combinations.  
So, the probability of this state is given by 2.  
As we have two possible combinations.  
Times 0.02 times 0.98 times 0.98.  
Which gives us about 0.03.  
Similarly, when we have 5MW unavailable.  
We multiply the unavailability of the 5MW unit with the availability of the 3MW units and so on to obtain the probabilities of the other states.  
In the last row, we have a state where all units are out.  
So, we simply multiply their unavailabilities.  
So, in this way we can build the capacity outage table.  
The last column is a cumulative probability.  
In the first state, the cumulative probability is 1.  
In the second state, is 1 minus 0.941192.  
Which gives 0.058808.  
In the third state, we have 0.02.  
Which is 0.058 minus 0.038 and so on.  
You should feel confident by now to derive this state cumulative probabilities.  
Let's now see a bit more complicated example using a recursive algorithm, while we use formula 52.  
In this example, a system consists of two 25MW units whose unavailability is 0.02.  
And 150MW units whose unavailability, meaning full outage is 0.007.  
And partial unavailability, meaning 20MW is out, is 0.033.  
Let's see the first step of the recursive algorithm.  
Where we add the first unit with a capacity 25MW.  
We first have 0MW out of service.  
So, X is 0.  
So, we are looking to estimate P0 using equation 52.  
While we are at the first unit, 25MW.  
The probability of state 0 is 1 minus unavailability of unit 1, 0.02 times the probability before adding the unit.  
Which is 1.  
Plus the unavailability 0.02 times the probability of 0.  
PX minus 25MW.  
The capacity of the unit.  
Which is negative.  
So, the PX of the previous state is 1.  
So, we have 1 minus 0.02 times 1 plus 0.02 times 1.  
Which is equal to 1.  
Similarly, when X is 25.  
So, the initial condition is positive.  
So, we have 1 minus 0.02 times 0 in the first term.  
In the second term, using equation 52.  
We have X minus C.  
Which is 25 minus 25 will give 0.  
And this is why we have here 0.02 times 1.  
And not 0.  
These altogether gives 0.02.  
Let's add now the second unit, again 25MW.  
When X is 0 we get the same as the first step.  
Which is P0 equal to 1.  
For P25 it is the first time here where we will use previous conditions.  
Again, emphasising this as it is important.  
In this step, we'll use the results of the first step as previous conditions.  
So, we have 1 minus unavailability times the probability from the previous step.  
0.02 plus 0.02 times the initial condition which is 1.  
This gives the probability of having 25MW out of service.  
When we add the second unit 2, which is 0.0396.  
The last step here is calculating the probability of having 50MW out of service.  
Again, we have 1 minus the unavailability times 0.  
Because our initial condition here is 0.  
Plus the product of the unavailability.  
And the probability of the previous condition.  
Where we had 25MW out of service.  
I will have 50MW, X minus 25MW.  
C the capacity.  
Which gives 0.0004.  
In step 3 now, we add the 50MW unit.  
Which is a multi-state unit.  
So, here we will use equation 53.  
Which refers to a generalised condition when units have derated states as the unit in our example.  
The unit now for example now has unavailability full outage 0.007.  
And partial availability 0.033.  
So, for P0, 0MW out of service.  
We have the availability 0.96 times 1 plus 0.033.  
The partial unavailability times 1.  
Plus the total unavailability 0.007 times 1.  
In order to calculate P20, P25 and so on we follow the same procedure as we did in the first two steps.  
Using, as previous conditions, the results from step 2.  
Try to solve these yourself at home.  
And please raise any issues you may face in doing so.  
Now, let's see the general equations for calculating frequencies and durations in the capacity outage table.  
So far, we are only calculating probabilities.  
The first step is to model the entire states based diagram with transition rates.  
Meaning using failure and repair rates.  
The next step is to aggregate, combine, identical capacity states into a new state.  
Here, the subscript i will refer to the identical capacity states.  
And k refers to the new merged state.  
So, the capacity outage of state k will be equal to each identical capacity state as we aggregate same units states into one state.  
So, we'll have Ck equal to C1, C2 and so on.  
Until Ci.  
The probability of state K, Pk is equal to the sum of the probabilities of the individual states.  
So, Pk is equal to P1, P2 and so on until Pi.  
The same with the frequency.  
So, we'll have Fk equal to the sum of the frequencies of all individual states.  
And finally, we have total departure rates from state k that we need to consider.  
Where we can see here we have plus minus lambda.  
The plus refers to transition to a state with higher availability capacity.  
And minus refers to a transition to a state with lower available capacity.  
And we have the formula here 54.  
Where lambda plus minus k is equal to the sum of the products of the probabilities and the transition rates.  
And then everything is divided by the total probability of state k.  
Let's see an example in application now.  
In this example, a system consists of two 25MW units and one 50MW unit.  
All units have failure rate of 0.01, failure per day.  
And repair rate of 0.49.  
First, we want to develop the state space diagram.  
Then, aggregate the identical capacity states.  
And then calculate the probability and frequency of each state.  
We have 3 units of 2 states each.  
So, we have 8 states.  
The first state is of course when all units are available.  
The second row, states 2, 3 and 4 is when one unit is out of service.  
The third row is when two units are out of service.  
And the last row is when all units are out of service.  
As a reminder, U means up.  
And D means down in this diagram.  
The transition rates between the different states, as we discussed in past examples too, are the failure and repair rates of the generation units.  
For example, the transition state 1 to states 2, 3, and 4 are the failure rates of individual units.  
And the transition back to state 1 are the repair rates of the individual units.  
Similarly, for the transitions between the states between the different rows in our state space diagram.  
So, basically you need to understand which units are up or down in each of the states.  
And use the correct failure or repair rates respectively between the states.  
I hope this will make sense by now.  
But please raise any questions you may have to your tutor.  
Let's do now some basic calculations looking at calculating the state probabilities and frequencies which we have in the first table here.  
For the first state all units are available.  
So the state probability is given by the product of the availability of each unit which is 0.98 which is calculated using the failure and repair rates of the units.  
The frequency of state zero is equal to the probability times the departure rate from state zero which is three times the failure rates.  
So three times 0.01 which gives 0.03.  
So we have 0.941192 the probability of state zero times departure rate 0.03 equal to 0.028283 and so on.  
For state two we'll have 25MW out of service as unit one is done.  
So we have 0.02 times 0.98 times 0.98 equals to 0.019 for the state probability.  
The departure rate from day two is mean one 0.49 plus lambda two 0.01 plus lambda three 0.01 which all together gives 0.51.  
I hope this is clear from the state space diagram of the previous slide.  
So the state two frequency we have 0.019 times 0.51 which gives 0.0097.  
The results are the same for states three and four only because we assumed same fair and repair rate for all the units.  
Please be careful with the data given in the problem to make sure to avoid easy mistakes.  
Let's see now state five where we have two units out of service.  
In particular units one and two.  
So 50MW are out of service.  
We have 0.02 times 0.02 the unavailabilities of units one and two times 0.98 the availability of unit three.  
So we have a state five probability equal to 0.000392.  
The departure rate of state five is mu two 0.49 plus mu one 0.49 plus lambda three 0.01 which gives 0.99.  
So the state five frequency is 0.000392 the state probability times 0.99 which is 0.00038.  
Again we get same results for states six and seven only because the failure and repair rates are assumed the same for all generating units.  
Let's see the last state where all units are out of service.  
So we have a product of the unavailability of all units as the state probability.  
So 0.02 times 0.02 times 0.02 which gives us 0.000008.  
The departure rate of state eight is equal to three times the repair rate.  
So three times 0.49 which gives 1.47.  
So the state frequency we get for a state eight is 0.000011.  
The second table in this slide shows how we can reduce this generation model to five states.  
From the top table we can see that we can aggregate the states with the same capacity out.  
So state one will be one state.  
States two and three can be merged, States four and five can be merged.  
States six and seven can be merged and state eight could be an individual state.  
So we now have five states with capacities out of service is zero, 25, 50, 75 and 100MW.  
In this table we show both the capacity out of service and in service.  
The probability of state one of the new reduce model is equal to the state one of the full model as will have the same state in both models.  
In state two of the reduced model however we sum the probabilities and frequencies of the states that are merged.  
So states two and three.  
For state three of the reduced model we sum the probabilities of frequencies of states four and five of the full model.  
And of state four of the reduced model we add the probabilities of the state six and seven of the full model.  
In this way we get the probabilities and frequencies of the states in the reduced generation model.  
So in this video we built on the reliability modelling or generating units we covered in the previous video.  
And we went into detail on creating the capacity of these tables which are very important concepts in generation reliability studies.  
We saw formulas about calculating the cumulative probabilities or the capacity out of this table.  
For two state and multistate generating units considering the derated states as well.  
We then discussed how to calculate the frequencies to of the different states and demonstrated how we can aggregate different states with identical capacities into a reduced generation model.  
This is very important when we have a system with many generating units as it happens in reality and the problem might become invisible to solve.  
In the next video we'll talk about calculating reliability indices or generation load systems and in particular laws of loads and laws of energy indices.  
    
# 2.7 Reliability Indices: Definitions and Applications   
## 2.7.1 Reliability Indices of Generation-Load Systems   
LECTURER:   
Welcome to the third video of section six, which is called Reliability Indices on Generation Load Systems.  
There are different reliability indices that can be used, but we'll focus on loss of load and loss of energy indices.  
Calculating the reliability indices of a system, any system, is critically important to understand how well it performs, if it actually performs it's intended operations as planned and as desired, and if not, do we need to improve it's reliability and how? So this is another very critical aspect of reliability modelling and analysis of power systems.  
So we mentioned in the previous video, that in generation load studies, we consider the system as and one point system.  
Basically we ignore the network and gather all the generation and demand and 1.10.  
In such a system, the reliability indices are calculated by comparing the available generation and capacity, against the system load curve.  
The system load curve will always be in the shape of the load duration curve, of which an example we'll see in this figure.  
I consider that you're aware of what a load duration curve is, if this is not the case, please ask.  
In the x-axis, the time period can vary, but is usually expressed for one year 8,760 hours.  
The y-axis will have the demand, here we note the peak demand.  
If for example we assume that the capacity of our generators in the system is CJ which is less than the peak demand, it means that there will be undelivered unsupplied load.  
So the first index is the loss of load expectation.  
We'll use the simplest possible load model, where each day is represented by it's daily peak.  
Then the individual daily peaks are arranged in descending order and the form and daily peak load variation curve.  
So there will be 365 discrete values in a year with their shape similar to the figure in this slide.  
Now, what does loss of load expectation actually mean? LOLE is the expected number of days in the specified period in which the daily peak load will exceed the available generation capacity, which will unavoidably result in load shedding curtailment.  
Basically as we have seen in the previous slide, capacity CJ was lower than the peak, which meant that load shedding will occur.  
The formula for calculating LOLE, is given in equation 55, which can be calculated from the capacity outage cumulative probability table.  
LOLE, can be calculated as the sum of the probability of loss of load on day i.  
In this equation, CI is the available generation capacity on day I, LI is the forecasted peak load on day i and n is the number of days in the period which is usually a year.  
As I forementioned, the load is modelled as a load duration curve which will compose by daily peak loads.  
Finally, it is worth noting that LOLE or loss or load probability, is one of the basic indices used in generation expansion planning.  
Let's now see an example, the generation system is the same as in the previous example in the previous video meaning two 25MW units and one 50MW unit, with the same failure and repair rates.  
The load data for a period of 365 days are shown below.  
And we want to calculate the LOLE index.  
The data we have in this table, are the daily peak loads in megawatts, and the number of occurrences of each of this peak load.  
So, the load duration curve, is derived by this table.  
So we have a peak load of 57MW for 12 days, 52MW for 83 days, 46MW for 107 days, 41MW for 116 days and 34MW for 47 days.  
Please note that the sum of the number of daily occurrences is 365 the number of days in a year, so we can build the load duration curve for a year from this table.  
The capacity outage probability table we see here, was calculated in the previous example.  
We'll then calculate LOLE by directly applying formula 55 and using the number of days and the peaks given in the table above.  
Be careful to notice, which cumulative probabilities are now replaced.  
So let's start calculating LOLE.  
The first time is 12, the number of occurrences of the 57MW peak, times the probability of 100MW the store capacity minus the peak 57MW.  
The second time is 83, the number of occurrences of the 52MW peak times the probability of 100MW minus the peak 52.  
And so on for the 46, 41 and 34MW peak loads.  
So in the first time, we are interested for the probability that 43MW will be out of service.  
43MW is between 25 and 50MW, so we go for the 50MW, so it is a cumulative probability of state three, 0.02.  
The same for the 47MW of a second time.  
In the third term 54MW which is between 50 and 75MW we go for highest, 75MW for which the cumulative probability is 0.000792.  
The same for the forth time, 59MW of capacity out of service, and the last time two which has 66MW out of service.  
For both forth and fifth term, we use the cumulative probability of state four of the capacity outage table, which has 75MW out service.  
So in this way we can simply calculate LOLE which in this example is equal 2.15108 days per year.  
Now, we solve this problem using cumulative probabilities.  
However, this problem can also be solved using the individual state probabilities PK which we'll not cover here, but feel free to try it yourself and let me know if you have any difficulties.  
Let's now talk about the very similar index loss of load probability or L-O-L-P in short.  
This reliability index is frequently used in vertically integrated power systems as the main index for generation expansion planning.  
A typical constraint that is used for generation expansion planning is that L-O-L-P should be lower than 0.5 hours per year.  
If this criteria is not satisfied, any current configuration or practices should be revised until this criteria will be fulfilled.  
In L-O-L-P the load duration curve is often represented by half - hourly data.  
L-O-L-P is calculated as in equation 56.  
Ti is a duration that the load will not be delivered for the i state of the generation capacity.  
If we look at this curve here, we can understand the meaning of Ti.  
So basically if we assume again the capacity ci in this figure ti is the time that load would be lost due to inadequate generation capacity.  
Note that duration can be expressed either as percentage value or hour per period value.  
X capital is the available generation capacity and x lower case is the state i generation capacity.  
Equally, L-O-L-P can be calculated by the sum of the probabilities of state i and the duration of states i.  
We would see in an application later on to make everything clearer.  
Next we'll talk about energy index, the loss of energy expectation.  
Will follow a similar approach as L-O-L-P.  
The expected energy curtailment is given by equation 57 here which is the sum of the products of the probability of state i and the curtailed, non - delivered energy at state i.  
Or alternatively, it can be expressed using the integral we see in 57 which considers the load duration curve.  
Later wi can be easily understood by looking at the figure in this slide.  
So basically considering again a capacity ci or xi at ti, the area that will not be supplied above xi is the energy that will not be delivered delta wi.  
The summation in 57 goes over all generation capacity states i.  
Basal loss of energy expectation LOEE, two more important reliability indices can be defined, the energy index of unreliability and the energy index of reliability where w refers to the total energy supplied.  
So the energy index of unreliability is given by the ratio of LOEE over the total energy supplied during the period we're interested in.  
The energy index of reliability is then given by one minus the energy index of unreliability.  
Things will be clearer if we see an example now.  
A system consist of a 30 MW and a 20 MW unit.  
The probability of the full output of the first unit is 0.85.  
The probability of partial output 15 MW is 0.1.  
And the probability of complete shutdown is 0.05.  
So the first unit has three states.  
The availability of the 20 MW unit is 0.95 and unavailability is 0.05.  
The load curve over an interval of 100 hours is shown below.  
And we want to calculate loss of load probability EIU and EIR.  
So in this example we're given the capacity state probabilities of the units and the load curve for 100 hours.  
From the load duration curve, we can easily notice that the peak load in the system is 40 MW with a minimal load of 10 MW.  
The first step is to beat the capacity outage probability table for this system which I would expect you should be able to do this by now.  
So I will skip this part and you can do yourself as homework.  
For example, the probability of state one is 0.85 times 0.95 which gives us the 0.8075 we have for state one.  
For state two, where we have 15 MW out, we have 0.1 times 0.95.  
So we get the 0.095 for state two and so on up to state six.  
Now let's solve this problem.  
The first column is the number of states, there are six states.  
We have the capacity in at the second column.  
And the probability of the state i at the third column.  
So far everything is given for the capacity outage probability table we built in the previous slide.  
The fourth column shows the deficit duration time ti in hours where deficit here refers energy not supplied.  
So when we have all generator units online 50 in, the 50 MW is higher than the pick of 40 MW.  
So the duration of state one here is zero.  
For state two, when we have 30 MW in, 30 MW is between 30 and 40 in the load duration curve that was given in the previous slide.  
So basically that is one sixth of the 100 hours.  
So we get 16.7 hours.  
When 30 MW that are available state three, then this is basically one third of 100 hours.  
When 20 MW are available, this is two thirds of 100 hours.  
Finally, when 15 MW are available, it corresponds to about 83.3 hours and zero MW available corresponds to 100 hours.  
In the fifth column, we have the product of the probability of state i and deficit duration which will be used for the calculation of LOLP.  
In the sixth column, we have the curtailed energy theta wi for each case.  
So basically, we need to calculate the area of the triangle at the lower duration curve as we have seen area for each capacity we have in each state.  
This is how we get the values of the sixth column.  
In the last column, we have the products of the state probabilities and then the energy not supplied.  
So having calculated this, let's calculate the reliability indices.  
LOLP is basically the sum of the fifth column.  
So we have 0+1.59+1.42 and so on which gives 6.85 hours per 100 hours or 6.85%.  
The LOEE is given by the sum of the last column.  
So we have 0+4+7.1 and so on which gives 54.3MWh.  
The expected index of unreliability EIU is given by the ratio of LOEE over the total energy over the period we are examining.  
This is basically the area of the whole duration care which is 2500 MWh.  
So we have 54.3 the LOEE over 2500MWh which gives us 0.0217.  
And finally EIR expected index of reliability is 1-EIU which is 0.9783.  
So far we talked about modelling of generating units and how to calculate the reliability indices and in generation load system using a single load duration curve.  
However there is an uncertainty in this low duration curve which we need to consider.  
The uncertainty in the load forecasting is becoming increasingly critical in power systems with the penetration of different technologies especially in distribution networks such as PV electric vehicles and so on.  
So it is important we include the uncertainty in the load forecasting in the computation of reliability indices.  
The load forecast or the load peak p.d.f is usually a normal distribution where we can see a seven step approximation in the example figure in this slide.  
So we have the mean, the centre point then plus minus one standard deviation plus minus two standard deviations and plus minus three standard deviations.  
The calculation of reliability indices is done for each load level individually.  
So the results shall be multiplied by this load probabilities we see in this figure.  
Note that seven values discrete points are given in this figure.  
Now let's assume a straight line per unit LDC that connects points zero and one and one and 0.04.  
So this is a normalised load duration curve.  
Now let's assume a straight line per unit LDC that connects point zero and one and one and o.4.  
So this is a normalised load duration curve.  
The forecasted peak load is 50MW and the standard deviation is 2%.  
When the standard deviation is given percentage it always applies to the mean.  
We were to calculate discrete peak loads and their probabilities.  
So in this table we see that peak loads and the corresponding probabilities.  
50MW is the mean so it is centrally placed.  
Then from the previous figure we have the mean 50MW plus minus one sigma, two sigma and three sigma.  
So we'll have the mean 50MW plus minus 1MW plus minus 2MW and plus minus 3MW.  
This is how we get these peak loads in the first row.  
And the probabilities of each of this peak demands are given by the load forecast p.d.f from the previous slide.  
So with half of the mean 50MW probability of 0.382.  
For the plus minus one sigma values 49 and 51MW and probability of 0.242.  
For the plus minus two sigma values 48MW and 52MW, a probability of 0.061.  
And for the plus minus three sigma values 47MW and 53MW a probability of 0.006.  
So basically we have seven different load duration curves.  
For each load duration curve we have to do different calculations.  
So for example for the last one with peak 53MW will calculate reliability indices and then multiply it by 0.006.  
For the one with 52MW peak load will multiply the calculable reliability indices by 0.061 and so on.  
In this way we'll get the expected values of the reliability indices more accurately accounting also for the uncertainty in the load forecasting.  
However very often the load duration curve is given steps as a multiple step model discrete points if you have the numerical data to do so.  
When the uncertainties are not included the load levels and their probabilities are given as the below or load level one, load level two, k and N.  
The probability of each load level is equal to the duration of each load level over the duration of the period p.  
Now if we want to take into account the uncertainties in the load forecasting then we need to apply the concepts we just discussed.  
And we need to do this for each load level.  
So if we take the load level k for example Lk will be considered the mean and then we'll have again plus minus one sigma, plus minus two sigma and plus minus three sigma as the example we just saw.  
So we multiply the ratio of a duration of a state over the total duration that we had when we were not considering the uncertainties with the probability corresponding to each load level.  
Again mean plus minus one sigma, plus minus two sigma and plus minus three sigma.  
In this video we discussed the key reliability indices of generation load systems including loss of load expectation, loss of load probability, loss of energy expectation and the energy index of unreliability or reliability.  
We also saw how we can use the load duration curve to derive these reliability indices which are highly critical in any reliability study you may wish to run as electrical power engineer.  
Finally we covered a very important timely concept the uncertainty in the load forecasting which has a formation is becoming increasingly relevant in the rapidly changing energy landscape.  
    
## 2.7.2 Generation Expansion and Operation Planning   
LECTURER:   
Welcome to the fourth video of section six, called generation expansion and operation planning.  
In this video, we'll discuss what generation expansion planning is, why it is important, and also go through the basic principles of generation expansion planning.  
We will also discuss the unit commitment method see an algorithm for estimating the expected production of generating units, and talk about operating reserves.  
So generation expansion planning is traditionally based on the reliability indices, this is why calculating this reliability indices that we've covered in previous videos is very important.  
The most frequently used reliability indices in generation expansion planning, is loss of low probability LOLP, and loss of load expectation LOLE.  
The generation expansion planning, is done over a planning period, usually quite big period, let's say 20 years, in which the Load will grow, and we need to have in place subsequent generation to cover meet this demand.  
Units are usually added when the reliability indices we're using go above a pre-specified threshold, which is usually regulated and has to be met by the electricity providers.  
The aim is to reduce these reliability indices when new generating units are added, so we'll come meet the targets of reliability indices.  
Basically as the load grows, our liability goes down, so we need to take actions by adding more generating units to keep the reliability indices below the pre-specified threshold.  
However, as we note in the previous video, there is a high uncertainty when projecting the actual future load.  
So it should be considered as a random variable.  
For simplification purposes or use an deterministic model in our analysis, an examples here.  
Let's see an example.  
A system consists of 540 megawatt units whose unavailability (FOR) outrage is 0.01.  
The peak load is 160 megawatt, and normalized low duration curve is a straight line connecting points zero and one, and one and 0.4. It has been decided to add additional 50 megawatt units with forced outage, an outage rate 0.01, to meet the projected future load growth of ten percent per year.  
The acceptable reliability level is LOLE, equal to 0.15 days per year.  
So this is the LOLE target threshold that we need to meet when adding new generating units.  
In what years must the units be committed in to meet the accepted system risk level? So let's see the solution.  
In the table we have in this slide, the first column shows the system peak load, and the rest of the columns show the LOLE in days per year, for the corresponding capacities we'll have, when we'll have the existing generating units and when we add the additional 15 megawatt units.  
So it will be a capacity of 200, 250, when one unit is added, 300 megawatts when two units are added, and 350 megawatts when, three units are added.  
So the first step in our solution will be to build the capacity probability outage table, for the existing 540 megawatt units.  
The second step is to calculate the LOLE for the system of this 5:0 megawatt units by varying the peak load.  
So in the second column in this table, we'll have calculated the low LOLE, where we'll have 200 megawatt installed capacity.  
We can see that when the peak demand is 160 megawatt basically year one, our criteria of LOLE equal to 0.15 has been exceeded.  
So this means that they new generating unit has to be added when the peak demand is 140 megawatt.  
Basically before we exceed the LOLE threshold.  
So by adding the new generating unit of 50 megawatt, we have an installed capacity of 250 megawatt.  
Now we have to repeat the LOLE calculations, with the five units being in place.  
This is shown in the third column.  
We see that now the LOLE threshold is exceeded when the peak demand is 200 megawatt basically in the third year.  
So now we'll have to add one more unit and calculate LOLE again.  
We see now that the LOLE of 0.15 is exceeded when the peak load is 250 megawatt, which is the fifth year.  
And finally, the last column, when we add the last unit, we repeat the same procedure, and the LOLE threshold of 0.15, is exceeded when the peak load is 300 megawatt, basically in year number seven.  
In this slide we see a graphical representation of what we had in the table.  
So basically it's the LOLE versus the years in the future or the peak load.  
In the first curve, we have reached the 0.15 threshold in the first year, and then we'll have to add a new unit.  
So we move to the second curve, where we'll have five times 14 megawatt, plus one more unit of 50 megawatt.  
And we see that the reliability index, LOLE goes down, shown with the dotted line here, to a new LOLE value.  
Now we see that in the second curve, we hit the LOLE target at year three, where we add one more 50 megawatt unit, and move now to the third curve.  
In the third curve, where we have an installed capacity of 300 megawatt, the LOLE threshold is met at year five, where we add one more 50 megawatt unit, and move to the fourth curve. In the fourth curve, we see the variability threshold is met at year seven, as we already discussed in the previous slide.  
  
LECTURER: So this figure in this light, shows a nice graphical representation of how LOLE changes over time, over the peak demand period, helping us to find, at which year we need to add more generating units, to meet the prespecified LOLE threshold, which was 0.15 in our example.  
Now, let's move on to talk about unit commitment and how to estimate the expected production of generating units.  
Basically what we mean by unit commitment, is a method that gives a priority list for loading of generating units and this is usually done based on specific production costs.  
So basically the cheapest unit go first and so on.  
Then the generating units, are order under the low duration curve as we see in the LDC examples in this figure.  
However, the position of the units, depends on the availability of the previously loaded units.  
What do we mean by this? Let's see the example of the LDC in the left hand side.  
When unit one is available, then we have this priority.  
So unit one goes first, and then you need two.  
However, when unit one is not available, then unit two needs to go first and then followed by unit three.  
However, this procedure can get quite complicated, particularly in real applications and big systems, where the number of generating units is large.  
So we will see a simpler computational procedure next.  
So let's see what this simpler procedure is.  
And will then do an example.  
The first step is to develop the priority list for generational unit loading.  
Looking at the production cost of the generation units.  
In the second step, we assume that the entire consumption is supplied from the first unit.  
Then we find the expected not supplied, curtailed energy and subtract it from the total energy supplied to customers.  
The results, so obtained, is the expected production of the first unit.  
Then in the third step, we assume that the consumption, is supplied from the first two units.  
We will again calculate expected, not supplied, curtailed energy, and subtract it from the total required energy.  
This gives the expected production of the first two units.  
The expected production of the second unit, is then obtained by taking away the first unit expected production, from the previous result.  
We finally repeat this algorithm for all the units on the priority list.  
We'll see an example in the next slide to make this clearer.  
So the LDC and the reliability indicators of two units are given in example eight of the previous video.  
We assume here, that unit two, the 20 megawatt unit has lower specific production cost, the unit one, the 30 megawatt unit.  
In that example, we have calculated that reliability indices LOL P E I U and E I R of the system.  
In this example we would like to calculate, the expected productions from both units.  
So, since unit two is cheaper then, it will be committed first according to the algorithm we have just seen.  
So this unit has two states, 20 megawatt and zero megawatt.  
As we see in the table, with probabilities of 0.95 and 0.05 respectively.  
Then duration of 20 megawatt is given by the low duration curve, and it is 66.7 hours for 20 megawatt, and 100 hours for zero megawatt.  
The curtailed energy theta Wi is given by the triangle from the LDC, as we saw in third example, which is 667 megawatt hours for 20 megawatt and 2,500 megawatt hours for zero megawatt.  
The final column gives the product of pi and curtailed energy.  
So, the expected production of unit two is 2,500 megawatt hours minus the 758.7 megawatt hours, which we get by the last column of this table, and is the expected energy not supplied, curtailed, when we'll have unit two in place.  
So following the second step of algorithm in the previous slide.  
It is the total energy is supplied to the customers.  
2500 megawatt hours, which is the area of the LDC minus the expected energy curtailed 758.7 megawatt hours.  
The curtailed energy LOEE, was calculated in the previous example eight, which was 54.3 megawatt hours.  
So the expected production of both units is the total energy 2,500 megawatt hours, minus the LOEE, 54.3 megawatt hours, which gives us 2,445.7 megawatt hours.  
In order to find the expected production of unit one, we subtract from this, the expected production of unit two.  
So we have 2445.7 minus 1743.1 megawatt hours.  
And we get an expected production of unit one, equal to 704.4 megawatt hours, which is much lower than the one of unit two, as unit one is more expensive.  
Now, let's move on to talk about operating reserves, which is another application of the reliability techniques that we covered.  
This reliability techniques are applied in short term operations planning.  
So first we'll have the unit commitment risk, which is basically the assessment, of which units should be committed in any period of time, in order to achieve an acceptable level of system risk...  
Which as we discussed, is pre-specified.  
The second one is the response risk, where we basically decide how the committed units should be dispatched. For example, how much power each unit has to generate, how much it should hold as spinning reserves, and so on.  
So let's talk about the unit commitment risk.  
Let's say at T equal to zero, the operator knows that he cannot commit any unit for T, as a function of hours.  
This is the so called lead time.  
So if the load grows or any unit fails, another unit cannot be started.  
Then the operator has to decide on committing units at T equals zero, and has to accept the risk of just supplying or not supplying, then demand during this time.  
The system risk level, as we said, is usually specified and load supplied and spinning reserves requirements, need to be determined.  
Now, the modelling is essentially the capacity outage probability table, where however the forced outage rate is now replaced with the outage replacement rate ORR.  
If the repair process is neglected during the lead time T, basically mu equal to zero, differential equations will give the probability of being in downstate, which is equal to one minus E in the power of the negative product lambda, and the lead time T, which can be approximated to the product, lambda times T, which is defined as the outage replacement rate ORR.  
Please note the units we'll use here.  
If lambda is in one over a year, then T should be in years.  
So now the outage replacement rate given by this equation, is used instead of forced outrage to build the capacity outage tables.  
Let's see an example, an application of this.  
A committed generation system consist of 210 megawatt units, 320 megawatt units, and 216 megawatt units.  
The failure rates in ORR for lead times of one, two, and four hours are given in the table below.  
If the acceptable risk level is 0.001, what is the peak load that requires spinning reserve for each of the lead times.  
So in this table we have in the first column, the units in the second column we have the failure rate of these units, and in the following columns will have the ORR for lead times of one hour, two hours and four hours.  
Please note that when we multiply the failure rate, for example three for the first unit, with a lead time two hours, we have to divided by 8,760 hours, the hours within a year, which gives us the ORR of 0.000685.  
We have for the first unit for a two hour lead time.  
Now let's see the capacity outage probability table.  
In the first column we have the states of the capacity out, and in the second column we have the capacity in.  
In the third column we'll have the accumulative probability for ORR equal to one hour, two hours and four hours, in the remaining columns.  
We follow the same approach but using ORR instead of FOR.  
So if we look at ORR equal to one hour, we can see that will fulfil the acceptable risk level of 0.001 up to the fourth row.  
So this basically means that we can supply 170 megawatts of spin demand and keep 30 megawatt in reserve.  
When we have ORR equal to two hours, the maximum peak load we can cover, is 130 megawatt and we have to keep spinning reserves of 70 megawatt.  
We see that above the 130 megawatt, the accumulative probability gets bigger than 0.001, which is our acceptable risk level.  
So this means that if the lead time goes up to two hours, the peak load we conserve reduces, which is a logical conclusion.  
Looking at the lead time of four hours, we get the same observations with a lead time of two hours, which is maximum peak demand of 130 megawatt, and spinning reserve of 70 megawatt.  
So this was an example of calculating the spinning reserves where we simply replaced the forced outage rate, with the outage replacement rate of the generating units.  
So the methodology is the same as we saw in previous examples, in previous videos, but the outputs conclusions are different as we are now using the outage replacement rate and not the forced outage rate.  
Try to work out this example yourself, and please raise any questions you may have.  
Summarising what we have covered in this video, we have started our discussions on generation expansion planning, and went through an example to see and define the time, the year basically, that new units need to be committed for meeting the pre-define acceptable system risk levels.  
We then discussed and approach with an illustrative example, on how to define the expected productions of generating units, based on their generation cost and for meeting again pre-specified reliability indices.  
We close this video by talking about operating reserves, which is another critical application of the reliability techniques we have covered, and demonstrated how we can use the new concept of outage replacement rate, instead of the forced outage rate of the generating units, to define the peak load and the amount of reserve services for different lead times, and it was shown that the bigger the lead time, the lower the peak load, and the higher the spinning reserves, which is unexpected.  
Conclusion.  
    
# 2.8 Reliability of Complex Systems: State Enumeration and Monte Carlo Simulation   
LECTURER:   
Welcome to the fifth and last video of section 6 called Reliability of Complex Systems, State Enumeration and Monte Carlo Simulation.  
In this video, we start our discussions with what state enumeration is.  
And how it can be used in power systems studies, before we move on to talk about Monte Carlo simulations.  
Which is a critical method that is widely used in all areas of reliability analysis.  
Particularly for complex systems.  
So, to begin with, in a power system there are different states which are enumerated.  
And then, each system state is analysed in turn.  
So, what do we mean by system state? A system state is determined by the status of all system components.  
Basically, which components are in service and which components are out of service.  
Please note, as discussed in previous videos, the sum of all state probabilities should be equal to 1.  
The state enumeration is often used for reliability analysis of composite transmission and generation systems.  
For example, using the DigSilent software.  
Which is very widely used among power companies worldwide.  
We'll now see an algorithm for state enumeration.  
The first step is to consider the next system state.  
Let's say k.  
Its probability is given by the equation we see here.  
Which is basically the product of the probabilities of the n components we have in the system, residing in the up or down state.  
That is basically the availability if the component a is in service.  
Or its unavailability if it is out of service irrespectively.  
This is based on the assumption that all the components are independent.  
The second step is to analyse state k using appropriate power system model.  
Where we basically aim to calculate the probability of the system failing to deliver its function.  
This probability is given by the some of the probability of failing to deliver its function in the previous state and the probability of state k.  
Which is given by the equation in step 1.  
So, for example if the system has not failed in the previous step.  
Pfs is equal to 0.  
And Pf will be equal to the probability of state k, Pk.  
The third step is to calculate the expected value of the reliability quantity V.  
Which is given by this equation.  
V can be any quantity but usually it is the expected energy not served or not supplied.  
So, we have again the expected value of the reliability quantity of the previous step.  
Denoted by S here.  
Plus the one in this state.  
Which is given by the product of the probability of this state.  
And the reliability quantity V.  
So, this is again a recursive approach.  
In the first step, we calculate the total probability of all enumerated states.  
Which is denoted by Pa0 here.  
So, we have Pa0 equal to the sum of Pa0s and the probability of this state k.  
We need to calculate the total probability as this is our stopping criteria.  
Basically, if 1 minus Pa0 is larger than a pre-specified threshold value.  
We return to step 1.  
If not, we stop our algorithm.  
Alternative criteria for stopping this algorithm can be the specifications of the outage order for simultaneous outages that will be studied.  
And this is typically 3rd or 4th order.  
The last point here is that the generating units are in general less reliable transmission components.  
So, a higher order of unit outages could be often studied.  
Let us now move on to discuss the probably most widely used method in all areas of reliability analysis, Monte Carlo Simulation.  
There is no software particularly running Monte Carlo Simulations.  
But there have been several methods using Monte Carlo Simulations that have been developed and can be used for such purposes.  
This method is particularly useful in complex systems in general.  
And not only power systems where we have a lot of components with up and down states.  
So, defining the overall system state becomes a very difficult task.  
Here, we will follow a similar approach as the state enumeration method with a difference, which is very important however.  
That the system states are randomly generated and not in a deterministic way.  
It is also worth noting that the Monte Carlo Simulations are often combined with state enumeration.  
Which we will see later on.  
We will next see an essential algorithm.  
The first step is to generate a system state by random generation sampling of system components.  
So, this is a fundamental difference.  
So, instead of just assuming that the component will be up or down.  
We randomly generate these states.  
The second step is to analyse the system state using appropriate power system model to calculate the reliability indicators.  
Then, in the third step, we'll test whether the conversion criteria is satisfied.  
If yes, we'll go to step 4.  
If not, we'll return again to step 1.  
In step 4, we have the final processing of simulation or reliability data obtained by the above loop.  
For example, expected energy not served, or loss of low probability.  
Now, let's see some important, essential features.  
Let's assume that Q is a system unavailability.  
And Xa is the 0 1 indicator variable.  
So, basically Xa equals 0 is if the system is in the up state.  
And Xa equals to 1 if the system is in the down state.  
Then, the expected value of unreliability is equal to 1 over n times the summation of a 01 indicator variables.  
The variance of the variable x is given by the second equation.  
Which is ultimately given by the difference between the unavailability and the unavailability in power of 2.  
The variance of the unavailability is next given by the variance of X, Vx over n.  
The number of samples, iterations.  
The coefficient of variation, alpha, is given by the following equation.  
Which is equal to the square root of the variance of unavailability over the unavailability.  
The number of iterations in a Monte Carlo simulation is given by the ratio of 1 minus unavailability over the coefficient of variation, alpha, in the power of 2 times the unavailability.  
Finally, the standard deviation of estimates sigma is equal to the square root of the variance of unavailability.  
Now, let's see some key conclusions.  
For a desired accuracy level alpha the required number of samples n depends on the system unavailability.  
But does not depend on the system size.  
Large systems are usually OK here.  
The second conclusion is that the number of samples n is inversely proportional to the system unavailability.  
The third conclusion is that the coefficient of variation can be used as the conversion criteria.  
We should note here that the variation of coefficient of EENS has the lowest convergence rate.  
The last conclusion is that the standard deviation can be reduced by decreasing the sample variance and increasing N.  
These conclusions are derived from the above equations.  
I hope this is clear, if not please ask.  
Let's talk now about this random number generation.  
The first point to note is that the random numbers are generated to determine the status of a component.  
Which can be either up or down.  
Or the value of any other probabilistic value.  
For this purpose, several random and generators are used.  
Which have some fundamental requirements.  
Firstly, the random number is uniformly distributed in the range 0 and 1.  
Also, there should be minimal correlation between random numbers.  
So, independence is desired between the random numbers.  
Finally, the repeat period should be very long.  
The following equation and concepts in this slide are just provided for your information.  
Please, go through this equation yourself.  
So, we will now move on.  
So, how are we going to use this random number.  
The essential idea is given here.  
Generate a uniformly distributed number U between 0 and 1.  
And then, calculate the random variable x from the cumulative pdf Fx.  
Please look at these diagram.  
So, the idea is that the random number U, between 0 and 1, is randomly generated as we see in this figure.  
So, basically for this value of U we get the value of x.  
Which is the inverse of the cumulative pdf Fu.  
In this approach, we follow tabulating procedure which refers basically to a look-up table.  
So, the interval 0 to 1 is divided into k sub-intervals.  
Which have the same length.  
1 over k.  
Let's assume k equals 500.  
Then, the discrete values of the cumulative probability pdf are midpoints.  
0.5 over k, 1.5 over k, 2.5 over k and so on.  
In this way, the generated random number U is in the i interval.' So, the random variable x is the inverse of the cumulative pdf at i minus 0.5 over k.  
However, there are some very convenient cumulative distributive functions.  
For example the exponential functions.  
Which we have seen before as well.  
So, the random number variable x is ultimately equal to minus 1 over lambda, the failure rate.  
Times the ln of 1 - U.  
The uniformly distributed random number.  
Also note that the variable 1 - U also distributes uniformly in the interval 0 and 1.  
Let's talk next about the normal and weibull distributed random variable.  
Starting with the normally distributed random variable.  
The numerical procedure was described earlier.  
The algorithm is as follows.  
We first generate a uniformly distributed number U in the range 0 and 1.  
Then, we calculate the normal distributed variable x.  
Where Q is the probability and z is a normalised variable.  
We have discussed in the second video of section 5.  
So, please revisit this video again, the second video of section 5 to refresh your memory.  
Now, if the uniformly distributed number U is larger than 0.5 and equal smaller than 1.  
Then, x is equal to z.  
If the number U is equal to 0.5.  
Then, x is equal to 0.  
And if the number U is larger equal 0 and lower than 0.5.  
Then, x is equal to minus z.  
Then, the probability Q is equal to 1 minus U, if U is larger than 0.5 and lower equal to 1.  
And equal to U if U is larger or equal 0 and lower or equal to 0.5.  
In a Weibull distributed random variable, we have the expressions we see at the bottom of this slide.  
Please, note and remember what we have said in the second video of section 5.  
That Weibull distribution is preferred over the normal distribution.  
Because the Weibull distribution offers analytical solutions.  
The problem can be solved analytically.  
Which does not offer this capability.  
Basically, there is no analytical solution.  
Now, since we talked about random generation of variables.  
Let's talk about the status of system components.  
The component is simulated with up availability and down unavailability states.  
Let's assume that Ui denotes the unavailability of component i.  
And then, we generate the random number U.  
If the generated number U is lower than the unavailability Ui.  
Meaning it is the range on the left side we see in this figure.  
Then, it means that the component is in the down state.  
If the randomly generated number U is larger than the unavailability Ui.  
Then, we are on the right side of this figure.  
And the component is in the up state.  
This is a very simple way of defining if the component is in the up or down state.  
Now, let's assume that the component i has two derated states whose probabilities are Pi derated 1, PD1 and Pi derated 2, PD2.  
So, we've seen this figure that we'll have more regions.  
So, we have Ui, Ui plus PD1, And Ui plus PD1 plus PD2.  
The randomly generated number U can be within any of these ranges.  
In the particular example, we have in this figure.  
U is lower than Ui plus PD1 plus PD2.  
So, the component i will be in the derated state 2.  
If for example the number U was in the first range.  
Meaning larger than 0 but lower than Ui.  
Then, the component would have been unavailable.  
If it had been in the second range.  
Meaning larger than Ui but lower than Ui plus PD1.  
It would have been in the first derated state.  
If the generated number U was larger than Ui plus PD1 plus PD2.  
Then, the component would have been fully available.  
I hope this is clear and it makes sense.  
It is also worth discussing the so-called variance reduction techniques in order to see how we can reduce the number of iterations, samples.  
As in many cases, these number of iterations can be thousands.  
So, what we aim to do is to reduce the sample variance Vx.  
Which can reduce the standard deviation of the estimated sigma.  
Which is equivalent to increasing the number of iterations.  
There are quite a few techniques that can be used here such as control variates, importance sampling, stratified sampling and antithetic variates.  
These are only provided here for you information.  
But it is important to know about this techniques as Monte Carlos simulations can be very computational demanding.  
So, knowing how to use and apply these techniques is highly desirable in many situations applications.  
We will then see two types of Monte Carlos simulations.  
The first one is independent or not sequential Monte Carlo simulations.  
In the Monte Carlo, one system state is completely independent from another.  
And each system state is defined by the states of its components.  
This is very similar to the state enumeration.  
So, if we assume Si is state of component i.  
Pfi is the probability of failure and Ui is randomly generated number distributed uniformly in the range 0 and 1.  
The success state, state Si equals to 1.  
Occurs if Ui is larger or equal to Pfi.  
Otherwise, Si equals 0.  
Which is the failure state.  
There is now a system with m components.  
S1, S2 and so on until Sm.  
Its probability is Ps.  
And the set of all systems states is G.  
The estimate expectation of the reliability index function Fs is given by the following equation.  
Where we have the product of this reliability index function Fs times the probability of this state Ps.  
With s being in the entire set of all possible system states.  
Here, we can think Fs as for the example the energy not supplied.  
And of course, the Ps can be expressed as the ratio between Ns.  
Which is the number of occurrences of state S over N, the number of samples.  
Now, the stopping criterion when the expected value of reliability function is sought is given in the next slide.  
I am not going to go fully in detail of the equations in this slide.  
We are just going to discuss the meaning and importance of this.  
In independent Monte Carlo simulations we have the so-called confidence intervals.  
Which we basically use to define the confidence in our output.  
So, basically if we use a confidence interval of 99%.  
We assume that we say with 99% confidence that our result is accurate.  
So, we use this confidence interval to define the number of iterations we need to run.  
Another stopping criterion is epsilon F.  
Which is a prespecified tolerance.  
If we know epsilon F, then the required or minimum number of iterations.  
Is given by equation 74.  
So we have a clearly specified number of iterations that we need to run.  
This is a well defined and widely used stopping criteria.  
There is one more stopping criteria where we calculate the probability which is given by equation 75.  
The point we need to understand here that they are well defined stopping criteria which we need to use to define our number of iterations.  
This is very important as Monte Carlo simulations can be very computationally and can demand in simulations.  
So having such stopping criteria is very important to define the number of iterations we need to run to optimise both the duration time and accuracy of our simulations.  
However the drawback of independent Monte Carlo simulation is that it can not give frequencies and durations.  
The advantage of independent Monte Carlo simulations is what we have just mentioned, the well defined stopping criteria.  
Let's see now an example.  
A system consist of two parallel components, whose failure rates are 0.001 failure per hour and 0.0024 failure per hour.  
Repair rates are 0.003 repair per hour and 0.005 repair per hour.  
we want to calculate system availability using analytical expression and Monte Carlo simulation.  
The solution from the analytical expression is given here.  
Where the system unavailability is 0.081 and the system availability is 0.91.  
The Monte Carlo simulation output is given in this figure.  
So after some time the simulation converges at 0.92.  
What we need to notice here are the oscillations we have at the beginning of the simulation.  
So we can not trust we can not have confidence at our initial simulations but we need to go beyond this oscillation we have at the beginning until our result converges with the pre-specified tolerance or confidence.  
Now let's talk about sequential Monte Carlo simulations which are the most popular Monte Carlo simulations.  
Note that this is a state duration sampling approach.  
The idea here is to study chronological events, chronological studies.  
So in the time domain, time series simulations and this is why this table of Monte Carlo simulations are very widely used.  
So we use this sequential Monte Carlo simulation in systems where subsequent states are highly dependent on previous states.  
So in situation where the states are not mutually independent.  
For example when the state in P+1 depends on the state at time T.  
Typical application include hydro, wind, storage and so on.  
We'll be sampling the probability distribution of the component state duration meaning the up and down times.  
then the sequential simulation of one year of system operation is repeated many times potentially thousands of times until convergence is obtained.  
The essential ideas presented in the figure in the right.  
So let's assume we have two components which can be either in the up or down states.  
the first two figures show the chronological operating cycles of the two components as they are cured from the random sampling of the probability distribution of the component state duration.  
The third figure shows the combination of the two first figures, the two operating cycles of the components which can have different shapes and operating states depending on the application.  
Now let's assume that two state models and exportation of pdf's are used.  
We'll go through the main steps of the global algorithm.  
The first step is to specify the initial state of each component which is usually the up state.  
Then in the second step we randomly sample the duration of each component residing in its present state.  
If Ui is a uniformly distributed random number and pdf is exponential then the state duration Ti is given by the negative ln of the ratio Ui over lambda i where lambda i is the failure rate if the component is in the up state or the repair rate if in the down state.  
The third step is to repeat step two in the given time span a year for example for all components, The chronological component state transition process has the form shown in the previous figure, so up and down states in chronological order for all the components.  
The fourth step is to calculate the chronological system state transition process by combining the chronological component transition processes of all components.  
This is shown by the third figure in the previous slide.  
The fifth step is to conduct system analysis for each different system state to obtain the reliability index F(s) and to calculate the expectation E(F).  
The key advantages of this approach is that it can be used to calculate frequency and durations.  
And also probability distributions of reliability indices can be obtained.  
For example if we have to calculate the energy not saved we don't get only the expected energy not saved but the entire probability distribution pdf or the energy not saved.  
What about convergence criteria in sequential Monte Carlo simulations.  
Unfortunately there are no explicit expressions as in the case of non sequential simulations.  
In this approach the total simulation time T should be sufficiently long, let's say 1000 years or even more.  
This is highly dependent on the problem.  
So we do this equation Monte Carlo simulation for T and then we repeat it for T plus vector T.  
If the expected value of the reliability index is almost the same in both cases then we stop.  
If not we increase T and we continue simulations.  
Another criteria is to keep the total simulation time T constant and to change the initial conditions of system components.  
If both results are about the same then we stop the simulation.  
Let's see a simple example now, assume a system has experienced three failures in eight years, the durations being 0.019 yr, 0.204 year and 0.346 year.  
The average failure duration is 0.189 years which is equal to the average.  
So 0.019+0.204 plus 0.346 over three.  
The failure frequency is 0.375 1/year which is given by three failures over eight years.  
And the failure probability is equal to 0.071 which is the duration times the frequency.  
So 0.189 times 0.375.  
In the following example the sample durations of the two components are given in the table below where x is the up state and y is a down state.  
We want to find the system states.  
So we are looking to find the chronological operating cycle of these two components.  
The question is then which are the failure states if the system is in parallel connection.  
So both components need to fail for the system to fail.  
And if the system is in series connection which means that if either of the components fail the system will fail.  
Try to solve this problem as homework.  
So in this video we start a round discussion with state enumeration before we move onto more complicated applications and in particular Monte Carlo simulations which is a very popular widely used technique.  
We talked about random number generation which is a very important aspect of Monte Carlo simulations and how we can determine the state of a component based on this randomly generated number and the unavailability of the component.  
Or it's probability of the related states.  
We then talked about two types of Monte Carlo simulations and in particular about non sequential and sequential Monte Carlo simulations.  
We also went through the global algorithm for solving sequential Monte Carlo simulations which method has significant advantages that justify its wide use in many applications.  
    
# 2.9 Introduction to Reliability of Transmission and Distribution Systems   
LECTURER:   
Hello, I am Victor Levi.  
In this section, we are going to study the reliability of composite generation transmission systems, reliability of radial and meshed distribution networks, as well as matters for the assessment of reliability costs.  
This is the last section dealing with the reliability analysis of power systems.  
The first topic, reliability of composite generation transmission systems is closely related to the last presentation in the previous section which explained the reliability analysis of complex systems.  
We are going to discuss the most frequently used reliability indices of composite generation transmission systems first.  
And then present a relatively general methodology that can be used in real life.  
This is a hybrid methodology, which combines state enumeration and Monte Carlo stimulation to generate a number of system states to be analysed.  
The power system analysis is then done using the optimisation model, called minimal containment model which belongs to the class of Optimal Power Flow models.  
These models were started in the fourth taught unit, Power System Operation and Economics, and you might need to revisit this unit.  
Reliability of distribution networks is started in the second part of the section.  
Reliability indices, most frequently used to describe reliability of distribution networks, are presented first.  
This is followed by a step-by-step explanation of the simplified analytical method that can be applied to radially-operated distribution networks.  
Reliability analysis of ring networks is presented next, whilst the final part presents a discussion on the total and partial loss of continuity in the case of general meshed networks.  
Reliability cost assessment is the last topic in this section.  
It is first distinguished between the utility and the customer's aspects of the cost of reliability, and it is then proceeded with the reliability cost assessment from the customer's perspective.  
To this end, assessment of the composite damage function is presented, which is followed by the damage function application for the reliability calculation of generation, composite generation transmission, and distribution networks.  
    
# 2.10 Reliability Analysis of Generation-Transmission Systems   
## 2.10.1 Reliability Indices of Generation Transmission Systems   
LECTURER:   
We are doing module Power System Dynamics & Quality of Supply We are doing Reliability of Power Systems now.  
We are starting a new section which is called 'Reliability of Transmission and Distribution Systems'.  
We will present, first, Reliability Indices of Generation-Transmission Systems.  
Generation transmission systems are networks where both generators and transmission networks are modelled.  
An example of Great Britain generation and transmission system is given on this slide.  
In England and Wales, transmission voltage levels are 400KV and 275KV.  
In Scotland. transmission voltage levels include 132KV as well.  
This means that distribution networks starts with 132KV voltage level in England and Wales and with 33KV voltage in Scotland.  
In the figure on this slide, so-called Western HVDC Link is also shown.  
This is a submarine 600KV DC cable, approximately 400km in length, that became operational in December 2017.  
We are going to present a few reliability indices which are used for the composite generation transmission systems.  
We will be analysing steady-state reliability of composite systems using the previously developed approaches.  
This is called adequacy assessments.  
The reliability indices can be calculated for the entire system when they are called system indices, or for each individual node, in which case, they are called 'Nodal Indices'.  
If the reliability indices are calculated for the peak load regime only and then expressed on a one-year basis, they are called 'Annualised Indices'.  
On the other hand, if the reliability indices are calculated for all load levels, they are called 'Annual Indices'.  
The most important indices are bolded on this slide.  
The students have to know the definitions.  
The first seven indices are basic adequacy indices.  
The first index is probability of load curtailment or PLC.  
This is a very important indice.  
PLC is the sum of probabilities of all states with load curtailments.  
The second index is 'Expected Frequency of Load Curtailments' or EFLC.  
EFLC is hard to define, and it is frequently replaced with 'Expected Number of Load Curtailments' - ENLC.  
ENLC is the sum of frequencies of all states with load curtailments.  
The third index is 'Expected Duration of Load Curtailments' or EDLC.  
EDLC is equal to probability of load curtailment times 8,760.  
The next index is 'Average Duration of Load Curtailments'.  
ADLC is equal to the ratio of the expected duration of load curtailments and expected number of load curtailments.  
The fifth index is 'Expected Load Curtailments', or ELC.  
It is the product of total load curtailed.  
Loads and frequency of states with load curtailments.  
The next index is very important.  
It is 'Expected Demand Not Served' or EDNS.  
It is the product of total curtailed load and probability of states with a load curtailment.  
The next index is also very important.  
It is 'Expected Energy Not Supplied' or EENS.  
It is calculated using equations 786.7, where probability of each state is equal to the product or the frequency and duration of that state.  
Five additional system adequacy indices are presented on this slide.  
They are used to compare reliability of systems of different sizes.  
The first additional index is a 'Bulk Power Interruption Index' or BPI.  
t is equal to the ratio of the EDNS and the annual peak loads.  
The second additional index is often used.  
It is 'Bulk Power Energy Curtailment Index', or BPECI.  
It is calculated as the ratio of the EENS and annual peak load.  
The next index is the 'Bulk Power-Supply Average MW Curtailment Index'.  
It is the ratio of the expected load curtailment and the expected number of load curtailments.  
Next index - Modified Bulk Power Curtailment Index is also often used.  
It is the ratio of the EDNS and the annual peak loads.  
The last index is 'Severity Index' or SI.  
Severity Index is bulk power energy curtailment index times 60.  
An example of the calculation of adequacy indices for the composite generation transmission system is presented on this and the next slide.  
The diagram of the analysed three-node system is shown in the first slide, dealing with reliability indices.  
Generators G1 and G2 are connected to nodes one and two, whilst load is connected at node number three.  
The task is as follows: Generation and line data for the simple three-node system are given in two tables below.  
Peak load is 110MW, losses of 5MW are added to the peak load, and line capacities in MW are obtained by multiplying the MVA capacities by 0.95.  
Analyse all first and second order outages and calculate adequacy indices, expected load curtailment, expected number of load curtailments, expected energy not served, and expected duration of load curtailments.  
The solution of this problem is presented on the next slide.  
We will talk about all columns in the table individually.  
The first column gives all the number of system states, while the second column presents components that are on outage.  
Please note that there are four generators - G1 connected at node one, and two generators, G2 connected at node two.  
This is important to calculate the probabilities of system states.  
For example, if G1 is on outage, then probability of Power Station 1 is four times generation availability to the power of three times generation unavailability, and so on.  
Third column presents state probability which is equal to the product of component availabilities and unavailabilities.  
Fourth column gives state frequency which is equal to the product of state probability and the sum of all failure and repower rates from that state.  
The fifth column shows the available capacity for supplied load taking into account both generator and line MW capacities.  
State duration is equal to 8,760 times state probability divided by the state frequency.  
Then expected load curtailment, ELC, is state frequency, ENLC, times curtailed load.  
Expected energy not served is 8,760, times state probability, times curtailed loads.  
And finally, expected duration of load curtailment is 8,760 times state probability.  
This slide concludes presentation of the first subsection.  
    
## 2.10.2 Reliability Calculation of Generation-Transmission Systems   
LECTURER:   
We are doing module Power System Dynamics & Quality of Supply.  
We are starting Reliability of Power Systems area.  
We are analysing Reliability of Transmission and Distribution Systems.  
In particular, we are studying Reliability of Transmission Systems now.  
We have already introduced reliability indices which are used for starting composite transmission-generation systems.  
We are now going to present outlines of methodologies for the reliability calculation of generation-transmission systems.  
Reliability calculation of generation-transmission systems is always done using computers and sophisticated software for power system analysis.  
Several commercial software tools have a computational engine for reliability calculations.  
For example, one of them is PowerFactory - DIgSILENT.  
Both methods, State Enumeration and Monte Carlo Simulation, can be used for reliability calculations.  
These methods were presented in the previous chapter.  
We will now present the major features of both methods.  
The characteristics of State Enumeration are: Firstly, Multi-step load duration curve is usually applied.  
Secondly, analysed system states are specified up to the pre-specified outage order.  
Then, calculated adequacy indices are those already presented.  
Next, frequency and duration method cannot be applied.  
And finally, stopping criterion is outage order which can be different for generation units and transmission lines, as well as for their combination.  
The characteristics of Monte Carlo simulation are: Firstly, either independent or sequential simulation is developed.  
Next, load levels can be either sampled or enumerated.  
Then, frequency and duration method can be applied in Sequential Monte Carlo Simulation only.  
And stopping criterion in Independent Monte Carlo Simulation is well-defined, but it is not so good in Sequential Monte Carlo Simulation.  
A global algorithm of a hybrid approach is presented on this slide.  
This approach can be applied to both State Enumeration and Monte Carlo Simulation.  
The outer algorithm loop is over different load levels.  
Multi-step LDC is typically used here and all steps are enumerated.  
For each load level, many system states are analysed.  
The system states are either randomly generated within Monte Carlo Simulation, or pre-specified within State Enumeration Approach.  
The most important block is System State Analysis.  
Depending on the phenomena modelled, this block can be very complicated.  
The reliability indices are updated if there are non-delivered loads in the analysed states.  
We are going to present one optimisation model, which is frequently used within the system state analysis block.  
The model belongs to the class of optimal power flow models, and we will present its version based on the DC power flow model.  
The DC power flow model is defined on this slide via equation 77.  
It was assumed that the select node is node 1, whose voltage angle is 0 radians.  
It is for this reason that there is no equation for node 1.  
The matrix equations tells that the active power injections in nodes are equal to the product of susceptance matrix, and unknown voltage angles.  
Calculation of matrix elements is given under the matrix equation which is followed by the calculation of active power flows over branches when voltage angles are known.  
Let's now look into a simple example.  
The problem is as follows.  
A 3-node network is shown in the figure below.  
Generator 2 is cheaper than Generator 1 and it operates at full output.  
Calculate branch power flows for the intact network and all single outages of lines and generators.  
Are there line overloads? Assume node 1 is the slack node.  
You will do this at home as homework.  
But there will be a hint for you.  
You will need to use DC load flow only for the analysis of intact network and generator outages.  
All branch outages can be solved by inspection.  
This means no DC load flow is required in such cases.  
The optimisation model we are going to present is called 'Minimum Load Curtailment Model'.  
The most important characteristics are given on this slide.  
It is a linear programming optimisation model if the DC load flow is applied.  
Next, load curtailments are modelled as additional or fictitious nodal generations at the load nodes.  
Next, curtailed loads are prioritised using weighting factors.  
The most important loads that should not be curtailed have highest priority factors.  
Then, objective function is minimisation of the sum of weighted curtailed loads at all consumer nodes.  
Finally, constraints of the MLC model are: DC flow equations, Generation limits, Branch flow limits, and limits on load curtailments.  
The mathematical definition of the MLC model is given on this slide within relations 78.  
The first line is the objective function.  
It is the sum of weighted load curtailment Ci at load nodes.  
All other relations are constraints of the MLC model.  
The first is the DC load flow model from previous slide written in the matrix form, with unknown load curtailments Ci in integration.  
It is not set for the select nodes.  
The second constraint is the overall load generation balance, but load curtailment Ci need to be included.  
The fourth constraint show lower and upper limits of active power generations.  
The fifth constraint gives the limits on load curtailments.  
And the last constraint specifies branch thermal limits.  
The unknown variables are vectors PG, then C, and finally theta.  
The model is solved using the standard simplex algorithm.  
Let's now look into another relatively simple problem.  
The problem is: Specify MLC model for the 3-node intact network given in the previous example.  
What is the load curtailment in each studied contingency case? The answer to the first part of the problem is given on this slide.  
There is only one load curtailment C3 at node 3.  
This load flow equations are specified for nodes 2 and 3, because node 1 is slack.  
The balance equation considers Generations PG1, and PG2, load curtailments C3 and a total load of 5 power units.  
Load curtailment C3 is between 0 and existing load of 5 power units.  
The last three constraints specify the thermal limits of branches 1-2, 1-3, and 2-3.  
Please calculate load curtailments for the outages of branches at your home.  
We have already pointed out that the block system state analysis is the most important and can get quite complex.  
A few additional features that can be included are listed in this slide.  
Nodal loads can be completely dependent, or independent, or partially correlated.  
Next, availability of primary resources can be modelled.  
Then, line common mode outages can be also modelled.  
Next, multi-state model for base generating units with derated states can be applied.  
Then peak generating units can be modelled by other model already developed before.  
Transformer substations, with and without spare transformer, can also be included.  
And finally, normal and adverse weather conditions can be modelled.  
The last point here is that system operation should also be modelled.  
For example, this means economic dispatching, unit commitments, getting reserve in the system right, etc, etc.  
This completes presentation in this subsection.  
    
# 2.11 Reliability Analysis of Distribution Networks   
## 2.11.1 Distribution Systems and Reliability Indices   
LECTURER:   
We are doing module Power System Dynamics & Quality Of Supply.  
We were studying reliability of power systems earlier.  
We are analysing reliability of transmission and distribution systems.  
We are starting to study reliability of distribution networks in this subsection.  
This is the first of the three presentations about the reliability analysis of distribution networks.  
We will first look into a few types of distribution networks in the UK.  
It should be pointed out that distribution networks can be very different to transmission networks.  
All distribution networks shown in this presentation are real life networks from one UK Distribution Network Operator.  
This slide presents typical 33kV networks in urban areas.  
The entire 132kV and 33kV networks down to 11kV and 6.6kV busbars are modelled into software package called 'IPSA'.  
The central part of the slide is 33kV busbars of the 132 to 33kV transformer substation alongside in the centre of Manchester.  
We can see that each primary substation, 33 to 6.6 kV, is supplied by two feeders.  
The next distribution level is 11kV and 6.6kV networks.  
The network shown on this slide is a urban underground 6.6kV network in the centre of Manchester.  
It is modelled in the package called 'DINIS'.  
Please note that the geographical map is also shown on this slide.  
This is very important for planning and design engineers.  
6.6kV cables are marked as blue lines whilst primary substations, 33 to 6.6kV, are denoted as red and white squares.  
These networks are built as interconnected networks but they are operated radial.  
The last level of distribution networks is low voltage or 0.4kV networks.  
The low voltage networks are entered in the geographical information system.  
LV cables are marked in blue colour.  
GIS systems in the UK do not have computation engines for power flow and short circuit calculations.  
The low voltage networks are radial networks.  
A summary of the UK Distribution Networks is given in the first bullet points.  
132kV and 33kV networks are meshed.  
Then 11 and 6.6kV networks are either radial or meshed, and low voltage networks are usually radial.  
Greatest contribution to unreliability comes from 11 and 6.6kV networks, and then low voltage networks that are operated radial.  
A typical 11 or 6.6kV feeder has one or more normally open points which can supply customers under outage conditions.  
This is the so-called backfeeding.  
Monte Carlo Simulation technique can be applied to both radial and meshed networks.  
Analytical methods can be applied to radial networks only.  
They are based on simplified unavailability calculation of components connected in series.  
The equations for reliability calculation of n components connected in series are presented at the bottom part of the slides.  
All equations 32 have already been derived.  
Please go through them on your own.  
Let's see the implementation of the above equations on a simple example.  
The problem is, a radial three-load point feeder consists of three sections which are protected by a circuit breaker.  
Section availability data are given in the table below.  
Calculate unavailability in hours per year of each load point.  
We will consider load point L3 first.  
Please note that each fault is cleared by the nearest circuit breaker.  
In case of load point L3, interruption of supplies occurs when either section A or section B or section C is faulty.  
Then the total failure rate is the sum of three failure rates 0.2, 0.1, and 0.15.  
Similarly, the unavailability of the load point L3 is the sum of three products, failure rate times repair time.  
Finally, resolution time for load point L3 is the ratio of unavailability and total failure rate.  
Please calculate these indices for load points L2 and L1.  
We will now present the reliability indices that are most frequently used in reliability calculation of distribution networks.  
The first group of indices are customer-oriented indices.  
The first index is 'System Average Interruption Frequency Index' or SAIFI.  
SAIFI is calculated as the ratio of the total number of customer interruptions and total number of customers served.  
Please note that the distribution companies call this index 'Customer Interruptions' or CIs.  
The second index is 'System Average Interruption Duration Index' or SAIDI.  
SAIDI is calculated as the ratio of the sum of customer interruption durations and the total number of customers served.  
Also note that distribution companies call this index 'Customer Minutes Lost' or CMLs.  
These two indices, CIs and CMLs, are being used in the UK to reward or penalise distribution companies for good or bad quality of supply performance.  
Next two indices are 'Average Service Availability Index' or ASAI and 'Average Service Unavailability Index' or ASUI.  
ASAI index is calculated as the ratio of the customer hours of available service and the customer hours demanded.  
On the other hand, ASUI index is the ratio of the customer hours of unavailable service and the customer hours demanded.  
It is also equal to 1 minus ASAI index.  
The next group of indices are load and energy-oriented indices.  
The first index is Energy Not Supplied, ENS, which is equal to the total energy not supplied by the system.  
ENS is the sum of products of average load times unavailability.  
The second index is 'Average Energy Not Supplied'.  
It is calculated as the ratio of the total energy not supplied and the total number of customers.  
We will now see how to apply the above formula for reliability indices calculation.  
The problem is: Consider the three-node network from previous example where load point indices are given in the second table.  
Calculate the customer and all oriented indices.  
Additional data are presented in the table below.  
To find SAIFI, we add products' load point failure rate times number of load point customers, and then divide by the total number of customers.  
To find SAIDI, we add products load point unavailability times the number of load point customers, and then divide by the total number of customers.  
ASAI index is calculated by subtracting products' unavailability, times number of customers for all load points from the product 8,760 hours, times total number of customers, and then divided by the latter.  
ASUI index is simply 1 minus ASAI.  
ENS is the sum of products' unavailability, times number of customers for the load nodes.  
Finally, Average ENS is ENS divided by the total number of customers.  
And this completes the presentation of this subsection.  
    
## 2.11.2Reliability Evaluation of Radial Distribution Networks   
LECTURER:   
We are doing module Power System Dynamics & Quality Of Supply.  
We are studying reliability of power systems area.  
We are analysing reliability of distribution networks.  
We are going to study reliability of distribution networks which are radial.  
We will apply the simplified analytical approach for the calculation of reliability of radial networks.  
Three essential equations for the calculation of total failure rate, total unavailability in hours per year, and total repair time were presented in the previous presentation.  
We will develop the analytical method gradually, starting from simple cases, then finishing with more complex cases.  
A simple radial network is shown on this slide.  
The figure mainly has four sections, denoted as 1, 2, 3, and 4.  
There are four letters - a, b, c, and d, towards four load centres - A, B, C, and D.  
There is only one incoming circuit breaker and letters are not protected.  
This means that in case of a fault on any section, or any letter, the incoming circuit breaker will open.  
This also means that all load points - A, B, C, and D, will have identical reliability indices.  
Failure rates and repair times for all sections and letters are given in the table, on the back part of the slides.  
The first table presents the reliability indices of load points A, B, C, and D.  
Reliability analysis is done by individual sections - 1, 2, 3, and 4, and laterals A, B, C, and D.  
They define the laws of the table.  
If a fault on any section or letter affects the considered load point, the reliability parameters, failure rate lambda, repair time R, and unavailability U, are entered into the appropriate fields.  
In this case, fault on any section or letter affects all load nodes - A, B, C, and D, and the table is full.  
The final node or reliability indices are presented in row marked as total, using the formula provided under the table.  
The additional load point data are given in the second table.  
It is asked to calculate system reliability indices.  
Please calculate SAIFI, SAIDI, ASUI and ASAI, as well as ENS and Average ENS, on your own at home.  
We are now going to investigate the effect of a lateral protection.  
This is usually done in real life.  
Fuses are installed at the beginning of a lateral.  
This means that the fault in a lateral is cleared by the corresponding fuse, and that other local points will not be affected.  
On the other hand, a fault in any free domain section is cleared by the incoming circuit breaker and all load points will be affected.  
Calculation of nodal reliability indices is shown in the table on these slides.  
Please note that the part of the table that corresponds to the feeder main sections is full, whilst the part corresponding to faults or laterals has diagonal structure.  
Please calculate system indices - SAIFI, SAIDI, ASUI, ASAI, ENS and Average ENS at home.  
The next task is to investigate effect of isolators or switches under reliability indices.  
Isolators are installed along feeder main, and they are not fault-breaking devices.  
This means that the main circuit breaker operates in case of a fault on a feeder main section.  
When a fault has been detected, an isolator can be opened and a breaker reclosed to supply other load points.  
This is always much faster than the repair of the faulty section or lateral.  
We will assume switching time is 30 minutes whilst repair time is four hours.  
Conclusion of nodal reliability indices is shown in the table on this slide.  
The structure of the table is the same as in the previous example, which means that the faults or sections and laterals affect the load points in the same way.  
However, there is difference in times needed to restore supplies.  
Supplies can be restored after either switching time, or repair time.  
Depending on the location of the fault and the considered load points.  
All switching times are marked in red.  
For example, in case of a fault on section three, incoming circuit breaker will open.  
The second switch can be used to isolate the fault so that load points A and B can be reconnected after 30 minutes, whilst load points C and D have to wait for four hours for section three to be repaired.  
Please calculate system indices - SAIFI, SAIDI, ASUI, ASAI, ENS and Average ENS at your home.  
We'll complete this presentation with studying the effect of load transfer, or backfeeding for the normally open points.  
Radial distribution feeders are usually connected to adjacent radial circuits through normally open points or NOPs.  
For when we get a fault, a part of feeder load can be supplied from the adjacent feeder through a NOP.  
The greatest effect, in this case, is for the load points furthest from the supply point.  
Let's see the nodal reliability is...  
This is presented in the table on this slide.  
Restoration of supplies at load points can now be done either from the original side, or from the NOP sides.  
Switching times for restoration from the original sides are marked in red.  
While switching times for restoration from the NOP sides are marked in green.  
For example, in a case of a fault on section one, electricity can be restored to load points - B, C, and D, after 30 minutes from the NOPs side, if the first switch is opened.  
Please go through all faults on your own.  
And this completes the presentation of this subsection.  
    
## 2.11.3 Reliability Evaluation of Ring and Meshed Distribution Networks   
LECTURER:   
We are doing module Power Systems Dynamics & Quality Of Supply.  
We are studying reliability of power systems.  
We are analysing reliability of distribution networks.  
We have done, so far, reliability indices for distribution networks, reliability analysis of radial distribution networks.  
We are now going to discuss reliability evaluation of ring and meshed distribution networks.  
We will first study ring distribution networks.  
A ring network is very common at 33kV in the UK.  
An example is shown in the figure on the slide.  
Full analysis can be done using the Monte Carlo simulation or State Enumeration.  
A simplified solution will be presented first.  
We will consider a dual transformer feeder which is shown on this figure.  
This is a typical supply structure at 33kV in the UK.  
We will assume that two busbars and circuit breakers are 100% reliable.  
We have already presented formula for simplifying the reliability calculation for components connected in series.  
We will need simplify the expressions for components connected in parallel.  
Their derivations are presented in one of the previous sections.  
Calculation of failure rate, repair time, and unreliability for two components connected in parallel is done using equations 35, presented on this slide.  
The corresponding equations for the three components connected in parallel are presented on this slide by equations 36.  
We will now solve the following problem.  
The ring network from the previous slide is studied.  
Failure rates and repair times are given in the table on this slide.  
Calculate failure rate, repair time, and other variability of the dual transformer feeder.  
We will first calculate the reliability indices for each transformer feeder.  
This is a serious connection of two components.  
Calculation of a component's failure rates, lambda 13 and lambda 24, unavailabilities U13 and U24, as well as the power times R13 and R24 is given on this slides.  
After having calculated a current indices for two transformer feeders, the overall reliability indices are obtained as a parallel connection of two equivalent components.  
Calculation of the overall failure rate, lambda PP, repair time RPP, and unreliability UPP, is shown on this slide.  
We can conclude this example with the following statements.  
The technique is not suitable for further development because weather effects, such as normal and adverse weather conditions, can not be modelled.  
Then schedule maintenance can not be included.  
Next, transient failures can not be adequate modelled and different modes of failure can not be considered.  
We will now discuss total loss of continuity and partial loss of continuity.  
Total loss of continuity is the term used when the entire load is disconnected or there is no path between the supply side and demand side.  
We will be using similar approach to the previous example that is formula for series and parallel connection of components.  
We will apply the following two equations.  
Average load disconnected is peak load times load factor, and average energy not supplied is average load disconnected, times annual outage time.  
We will do the following problem.  
Consider meshed ring system with two load points, failure rates of lines 4-7 are 0.02, of busbars 1-3 are 0.01, repair times of lines 4-7 are 10 hours, and the busbars 1-3 are five hours.  
Load points 2, peak load is 20MV, load factor is 0.75, and there are 2,000 connect customers.  
Load point 3, peak load is 10MW, load factor is 0.75, and there are 1,000 connected customers.  
Calculate reliability indices using approximate expressions for series and parallel connection of components.  
To solve this problem, we need to define outage events first.  
An outage event is defined for each load point separately.  
In case of our network, it is the second-order or third-order connection of parallel components.  
For example, load point 3 is disconnected when lines 6 and 7 are on outage.  
After having identified all outage events, the total reliability... And this is calculated as a series connection of all outage events.  
The solution to this problem is shown in the table on the slides.  
Outage events are separately defined for load points 2 and 3.  
The main conclusions are: there is more contribution from second-order and negligible contribution from third-order events.  
And main contribution comes from the busbar faults which are the first-order events.  
We are now going to talk about the partial loss of continuity in distribution networks.  
A 'Partial Loss Of Continuity' or PLOC occurs when a part of the load cannot be supplied.  
First-order and second-order outages are usually studied.  
Selection of second-order outages can be based on the following rules.  
All outages are studies if the number of components is small.  
We can manually determine from experience which outages are critical.  
The third-order minimal cut sets can be used to identify second-order PLOC events.  
All second-order combinations from each third-order minimal cut set for the considered load point are considered.  
Once the outages to be studied are defined, we can start to analyse then.  
To this end, a load flow model needs to be applied to find out whether network constraints have been violated or not.  
Then circuit overloads and voltages outside the permissible limits are usually considered.  
Finally, load curtailment or sheddings can be calculated in several ways.  
Load can be shed at the receiving end of the overloaded line.  
Or load is reduced proportionally at all load points that can affect the overload.  
Or optimal load shedding is done by applying the minimal load curtailment model.  
Further points that needs to be built into the reliability analysis are mentioned on this slide.  
Firstly, protection failures.  
For example stuck circuit breakers and busbar failures should be considered.  
Then transient and temporary failures need to be studied.  
The standard classification of outages is: Permanent outages - that is damage to components is being done.  
Temporary outages - there is no damage, suppliers are restored by manually switching, or fuse replacement.  
Transient outages - there is no damage, supplies are restored by automation.  
Then scheduled maintenance should be included in the analysis.  
Next, weather effects should be modelled and more complex configurations should be studied, etc.  
And this concludes the presentation in this sub section.  
    
# 2.12 Reliability Cost Assessment   
LECTURER:   
We are doing module Power System Dynamics & The Quality Of Supply.  
We are starting Reliability of Power Systems.  
We are analysing reliability of distribution networks.  
We have done so far: The reliability indices are related to the distribution networks.  
Reliability analysis of radio distribution networks and reliability analysis of meshed and link distribution networks.  
We are now going to study the last section - Reliability Cost Assessment.  
This section considers the cost of outages.  
We are going to present essential principles first.  
All cost in power industry can be classified as investment or capital cost for new components then operational costs, such as maintenance and losses costs, as well as costs of outages.  
A typical curve cost versus reliability is shown in the figure on this slide.  
We can see that when capital investments are increased, outage costs are decreased and reliability is improved.  
It is also clear that there is an optimal reliability point for which the total costs are minimal.  
Outage costs can be experienced by utility or customers and society.  
It has to be specified from whose perspective the costs are looked at.  
Some of the utility outage costs are: Loss of revenue from customers not served.  
Loss of incentive reward from the regulatory framework in the UK and increased expenditure due to maintenance and repair.  
On the other hand, customer outage costs are: Industry costs due to lost manufacture, damaged equipment, etc.  
Residential customer costs such as spoiled deep frozen food, alternative heating, etc.  
Costs difficult to quantify such as loss of convenience, looting, rioting, etc.  
We will now look into the outage costs from the customer's perspective.  
Outage costs experienced by customers are defined with the aid of the so-called customer damage functions.  
Customer damage functions can be determined by using one of the three methods.  
Contingent Valuation Method, or Direct Costing Method, or Indirect Costing Method.  
The first method, contingent valuation method, refers to customer willingness to pay to avoid an interruption, or customer's willingness to accept compensation for having an interruption.  
Please note that WTA values are significantly higher than WTP values which is logical and to be expected.  
The most recent study in the UK in 2013 showed that one non-supplied kWh was around 17 pounds, which is a roughly 100 times the cost of one supplied kWh.  
The second group of methods are direct costing methods.  
They are used to evaluate direct costs associated with particular outage scenarios.  
They are applied in industry and commercial branches.  
The third group of methods are indirect costing methods.  
The basic method is economic principle of substitution, that is valuation of a replacement good is used to measure worth of the original good.  
It is applied in the residential sector.  
For example, hypothetical insurance policy to compensate for possible interruption effects can be developed.  
The total customer damage function is composed of customer damage functions by industry sectors.  
One Sector Customer Damage Function is defined for each sector.  
The following essential principles for determining a sector customer damage functions are: Unit interruption cost is a function of interruption duration for a sector.  
Next, there are seven main sectors: Large users, industrial, commercial, agriculture, residential, governmental sectors.  
To find the Sector Customer Damage Function, reported customer interruption costs in pounds are normalised using the annual peak in pounds per kilowatt peak and then the values are obtained.  
Then the weighted average unit interruption cost for each section is calculated.  
Here, the following concept is used.  
If an interruption duration is short, then the weight is percent of the annual peak demand.  
And if interruption duration is long, then the weight is percent of the annual energy consumption.  
The diagram presents curves interruption costs in pounds per kW peak demand versus interruption duration in hours for five sectors.  
It can be seen that electricity interruptions in offices are valued most, whilst interruptions in residential and agricultural sectors are valued at least.  
After all sector customer damage functions are determined, the Composite Customer Damage Function can be calculated.  
The following basic principles must be followed.  
Firstly, unit interruption cost is a function of interruption duration for a customer mix at a bus, in an area, or in a whole system.  
Secondly, customer mix in terms of energy consumption all peak demand percentages must be known.  
If the interruption is shorter than 30 minutes, then the weighting factor is percentage of the annual peak load.  
And finally, if the interruption is longer than 30 minutes, then the weighting factor is percentage of annual energy consumption.  
A piecewise linear composite customer damage function versus interruption duration is shown on this slide.  
We are now going to discuss how the composite customer damage function can be applied when studying the generation, composite, and distribution systems.  
We will start with the generation systems.  
We have already shown how to calculate the Expected Energy Not Served, or EENS.  
This is given by equation 80.1.  
The Expected Interruption Costs or EIC in pounds per year can be determined using the equation 80.2.  
We can see that the EIC is equal to the products of Curtail Load, Ci, times Frequency Of Event i, Fi, times Customer Damage Function for Duration, Di, for all events, i.  
In case of sequential Monte Carlo simulation, the expected interruption cost is calculated in a different way.  
This is shown by the relation 80.3.  
To calculate the reliability of composite systems, we have to find the minimum load curtailment model.  
In the minimum load curtailment model, the objective function can be modified.  
Weighting factors, wi, can be replaced with customer damage functions at node i.  
This is given by equation 81.1.  
Calculation of nodal and system expected energy not served is given by equations 81.2.  
Whilst expected interruption costs are determined using equation 81.3, relations 81.2 and 81.3 are analogous to relations 80.2 and 80.3 on the previous slides.  
Finally, we can apply the same approach to calculate expected interruption costs for distributions networks.  
We can use equations 81 for this purpose.  
And this completes the presentation of the subsection on Reliability Cost Assessments.  
     

